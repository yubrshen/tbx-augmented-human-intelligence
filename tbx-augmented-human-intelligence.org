#+TITLE: tbx (toolbox) for productivity in information processing

* Introduction

This is my collection of know-how and utilities to make my coding as well as a shell script more convenient and productive.
Another purpose is to limit the surface of my tool chains so that I can be productive.
Ergonomically, the tool chain surface needs to be limited for human to master it comfortably and fluently.

In this document, not only scripts will be produced but also sample code segment and instructions would be shown.
This document embeds code with literate programming. The code can be generated
from this document, if needed. But most of the time, the code servers as
example, and illustration.

There will be organized into groups. One of the groups will be file utilities,
another group will be pre-processing for machine learning.

They will be mostly higher-level wrappers of the existing libraries.
This will serve the purpose of less memory overload.
Using these groups of utilities you can reduce the need to remember numerous libraries.

There may be many useful software libraries but I need to have effective entry
point
so that I can get my job done quickly reducing the load of memory and the load of searching the right tool.
It is vitally important to have personal toolboxes to be productive, as one can be sure to be familiar with the toolbox.
With these personal toolboxes, the API surface can be focused and limited to suit one's needs and habit.

In broader sense, there should research and effort on how to augment human intelligence (AHI) with computation tools.
For the purpose,
ergonomic tool surface may be an interesting research area.

* Resolution between mindmap and org-mode

I will use mindmap for knowledge acquisition at the top level, and for
thought exploration purpose, as the 2D dimensions is still better than org-mode's mainly
1D dimension.

I will use org-mode for extensive narrative of text. I may use emacs text-mode for
formatting some mindmap entries.

The drawback of mindmap is that

- it's still not possible to publish directly from mindmap.
- it's hard to search the mindmaps.
- it's much less effective to write large chunk of texts, without the auto
  completion help that's available in emacs.
- It's not possible to do version control effectively on mindmaps.

The idea combination would be to use emacs org-mode as the medium, but make it
possible to render and present the content of org-outline into mindmaps.
It might be possible, like a mindmap viewer off emacs, like one can view PDF
file in emacs.

* Unsolved problems

Here are records of unresolved problems, to save repeating effort.

** How to keep my notes easier to search over my whole computer?

I have lots of notes scatter in Freeplane files, org files, etc. I'd like to be able to search them for key words.
For examples, I'd like to know the notes about "TensorFlow" in all my files.

I might write a wrapper utility to find all the files scatter, and then search
in them.

** Not able to view *.mov file on Ubuntu with VLC and totem: alternative solution: use mplayer

For VLC, here is the error message:
as of[2017-11-21 Tue 09:59]
#+BEGIN_EXAMPLE
  Failed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory
#+END_EXAMPLE

Following the suggestion from https://askubuntu.com/questions/13487/gnome-mplayer-failed-to-open-vdpau-backend-libvdpau-nvidia-so-error
did not work, as it suggested to add:

The following with sudo would not evaluate with C-c C-c
#+BEGIN_SRC shell
  sudo ln -s /usr/lib/vdpau/libvdpau_nvidia.so.1 /usr/lib/libvdpau_nvidia.so
#+END_SRC

#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence
: 1

The following is the way to execute commands
"Evaluation of this shell code block is disabled" emacs babel with sudo in babel:
#+NAME:
#+BEGIN_SRC emacs-lisp
  (let ((default-directory "/sudo::"))
    (shell-command "ln -s /usr/lib/vdpau/libvdpau_nvidia.so.1 /usr/lib/libvdpau_nvidia.so"))
#+END_SRC

But I checked the file/link has aleardy existed:

#+BEGIN_SRC shell
Pybites.  ls -lt /usr/lib/vdpau/libvdpau_nvidia.so.1
#+END_SRC

#+RESULTS:
: lrwxrwxrwx 1 root root 55 Nov  4 12:59 /usr/lib/vdpau/libvdpau_nvidia.so.1 -> /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1

I chased the symbolic link:

#+BEGIN_SRC shell
ls -lt /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1
ls -lt /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1
#+END_SRC

#+RESULTS:
| lrwxrwxrwx | 1 | root | root | 46 | Nov | 4 | 12:59 | /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1 | -> | /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1 |
| lrwxrwxrwx | 1 | root | root | 25 | Nov | 2 | 12:42 | /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1          | -> | libvdpau_nvidia.so.384.98                      |

#+BEGIN_SRC shell
ls -lt /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.384.98
#+END_SRC

#+RESULTS:
: -rw-r--r-- 1 root root 888288 Oct 26 14:40 /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.384.98

so at the end of the symbolic link, the target file did exist!

But vlc still complainted.

The problem with totem is simply just crash.

The alternative of using mplayer to view the same file worked. So the case is closed for now,[2017-11-21 Tue 10:23]


* Handy Machine Learning and Data Science
** Pre-processing for machine learning

*** prepare_training_samples

    Move the samples in path according to their categories into their corresponding directories named by their categories.
    This is a convention in Keras deep learning.

    The determination of the category for a sample (file) is determined by the function category_f.
    It should raise ValueError exception if there is no category can be found for the sample.
    If there is no category found for a sample (file), then do nothing against (pass).

    #+NAME:prepare_training_samples
    #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
      def prepare_training_samples(path, category_f):
          path = os.path.expanduser(path)

          for f in os.listdir(path):
              try:
                  category_gory_dir = path + category_f(f) + '/'
                  mkdir_if_not(category_dir)
                  shutil.move(path + f, category_dir)
              except ValueError as e:
                  pass
    #+END_SRC
    Use shutil.move is considered more higher level than os.rename.

**** category_f

     Categorize the training data for you to file of a training center computer category based on the computer depository make directory if needed then move that piece of data into that corrupt responding categories I can generalize the function of category for a training file (image)

     An instance of category_f to determine the category of a file,
     by the first segment of the proper file name (the segments are separated by dot '.'.

     #+NAME:category_f_by_name
     #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
       def category_f(file_name):
           file_name = os.path.basename(file_name)
           proper_name = os.path.splitext(file_name)[0]
           return proper_name[:proper_name.index('.')]
     #+END_SRC

*** Randomly select a sublist

 #+NAME:random_sublist
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
   lst = [1, 2, 3, 4, 5, 6]
   def random_split(lst, x):
       import random
       random.shuffle(lst)

       return lst[:x], lst[x:]

   train, valid = random_split(lst, 2)

 #+END_SRC

*** validation_split

 #+NAME:validation_split
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
   def validation_split(train_dir, valid_dir=None, valid_percentage=0.01):
       """
       Splitting from training set samples for validation.
       The training samples are in train_dir.
       The validation samples should be in valid_dir.
       The valid_percentage is the percentage of the training set to be validation.

       It is assumed that train_dir have samples organized into subdirectories named by categories.
       """
       from pathlib import Path, PurePosixPath
       import os, shutil
       valid_dir = valid_dir or PurePosixPath(train_dir).parent.joinpath('valid').as_posix()
       pathlib.Path(valid_dir).mkdir(exist_ok=True)
       for d in os.listdir(train_dir):
           lst = os.listdir(train_dir+d)
           valid_len = int(len(lst)*valid_percentage)
           valid_lst, _ = random_split(lst, valid_len)
           p_valid_sub = valid_dir+d
           pathlib.Path(p_valid_sub).mkdir(exist_ok=True)
           for f in valid_lst:
               shutil.move(train_dir+d+'/'+f, p_valid_sub)
 #+END_SRC

** Confirmation of GPU working with TensorFlow

 #+NAME:if-GPU-works
 #+BEGIN_SRC python :noweb yes :tangle ~/tmp/verify_gpu_tensorflow.py :exports none
   import tensorflow as tf
   with tf.device('/gpu:0'):
       a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
       b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
       c = tf.matmul(a, b)

   with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
       print (sess.run(c))
 #+END_SRC

 Below output from the shell console where jupyter notebook server is run shows that GPU with TensorFlow is working:

 2017-08-08 10:27:53.180144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180176: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180181: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180185: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.528010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
 2017-08-08 10:27:53.528649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
 name: GeForce GTX 1070
 major: 6 minor: 1 memoryClockRate (GHz) 1.645
 pciBusID 0000:01:00.0
 Total memory: 7.92GiB
 Free memory: 7.32GiB
 2017-08-08 10:27:53.528682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
 2017-08-08 10:27:53.528692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
 2017-08-08 10:27:53.528713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
 Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0
 2017-08-08 10:27:53.609874: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0

 MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629104: I tensorflow/core/common_runtime/simple_placer.cc:847] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
 b: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629124: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/gpu:0
 a: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629131: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/gpu:0


** Recommended reading for data scientist

 These are content of substance:

 http://neuralnetworksanddeeplearning.com/chap4.html

 http://blog.kaggle.com/category/winners-interviews/

 https://distill.pub/

** About GPU/Nvidia

*** What is CUDA and cuDNN?
      CUDA - API/Language to talk to the GPU.
          CUDA is NVIDIA’s language/API for programming on the graphics card. I’ve found it to be the easiest way to write really high performance programs run on the GPU.  <https://developer.nvidia.com/cudnn>
      cuDNN - library for Deep Learning using CUDA.
          cuDNN is a library for deep neural nets built using CUDA. It provides GPU accelerated functionality for common operations in deep neural nets. You could use it directly yourself, but other libraries like TensorFlow already have built abstractions backed by cuDNN.


* Handy software engineering
** File handling

 This group should complement shutil and pathlib of Python. (shutil is of higher level than os package. pathlib is an object oriented for Path concept.)

 With pathlib, mkdir_if_not can be directly implemented. This may be revisited to use pathlib.

 #+NAME:mkdir_pathlib
 #+BEGIN_SRC python :noweb yes :tangle :exports none

   Path.mkdir(mode=0o777, parents=False, exist_ok=False)

       Create a new directory at this given path. If mode is given, it is combined with the process’ umask value to determine the file mode and access flags. If the path already exists, FileExistsError is raised.

       If parents is true, any missing parents of this path are created as needed; they are created with the default permissions without taking mode into account (mimicking the POSIX mkdir -p command).

       If parents is false (the default), a
 all I needed is to change the build location and point it to '../build' directorymissing parent raises FileNotFoundError.

       If exist_ok is false (the default), FileExistsError /media/yubrshen/DATA/ai-studyis raised if the target directory already exists.

       If exist_ok is true, FileExistsError exceptions will be ignored (same behavior as the POSIX mkdir -p command), but only if the last path component is not an existing non-directory file.

       Changed in version 3.5: The exist_ok parameter was added.

 #+END_SRC

 Also pathlib provides touch function.
 #+NAME:touch_pathlib
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   from pathlib import Path

   Path('path/to/file.txt').touch()
 #+END_SRC

 I should always do expand user (~) for pathname to be sure that they are absolute path to avoid trouble down the road of further processing in all my libraries.

*** Preamble

    Import etc.

    #+NAME:preamble_file
    #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
      import os, shutil
    #+END_SRC

*** mkdir_if_not

    Make directory specified if it does not exist.
    It returns the tuple of path of the directory and the boolean wthether the directory exists (should by true).
    It handles the exception that the directory might be created after checking its existence.

  #+NAME:mkdir_if_not
  #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
   def mkdir_if_not(path):
       path = os.path.expanduser(path)
       if not os.path.exists(path):
           import errno
           try: # use try to avoid repeated creating the directory, if it's created after the above checking
               os.makedirs(path)
           except OSError as e:
               if e.errno != errno.EEXIST:
                   raise
       return path, os.path.exists(path)
 #+END_SRC

*** unzip

    unzip a file specified by file_zipped to the directory specified by target_path,
    making sure the target_path do exist.

 #+NAME:unzip
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
   def unzip(file_zipped, target_path):
       target_path = os.path.expanduser(target_path)
       mkdir_if_not(target_path)
       import zipfile
       with zipfile.Zip2017-08-08 10:27:53.180144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180176: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180181: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180185: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.528010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
 2017-08-08 10:27:53.528649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
 name: GeForce GTX 1070
 major: 6 minor: 1 memoryClockRate (GHz) 1.645
 pciBusID 0000:01:00.0
 Total memory: 7.92GiB
 Free memory: 7.32GiB
 2017-08-08 10:27:53.528682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
 2017-08-08 10:27:53.528692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
 2017-08-08 10:27:53.528713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
 Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0
 2017-08-08 10:27:53.609874: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0

 MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629104: I tensorflow/core/common_runtime/simple_placer.cc:847] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
 b: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629124: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/gpu:0
 a: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629131: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/gpu:0
 File(file_zipped, 'r') as zip_ref:
           zip_ref.extractall(target_path)
 #+END_SRC

*** random_file_name

    Generate a random file name with suffix as parameter.

 #+NAME:random_file_name
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   import random, string, os

   def random_file_name(suffix, length=10):
       return ''.join(random.choice(string.lowercase) for i in range(length)) + '.' + suffix

 #+END_SRC

 #+NAME:random_file_name_test
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   file_name = random_file_name('txt')

   status = os.path.exists(file_name)

   def touch_old(fname, times=None):
       with open(fname, "a"):
           os.utime(fname, times)

   status = os.getcwd()
   import pathlib
   pathlib.Path(file_name).touch()
   status = os.path.exists(file_name)


 #+END_SRC


*** Finding files


**** Find files by modification time

Find files that are more than 10 days old:
#+BEGIN_SRC shell
find -mtime +10
#+END_SRC

Find the top level directory (-type d) for the current directory.
#+BEGIN_SRC shell
find -type d -maxdepth 1 -mtime +15
#+END_SRC
-type f
for ordinary file, non-directory

-name *.txt
for name pattern

Find the top level files/directories more 15 days old, and remove them recursively and forcefully.
#+BEGIN_SRC shell
find -maxdepth 1 -mtime +15 -exec rm -rf '{}' \;
#+END_SRC

**** Find files by extension, or type

   The following snippet works, but it took a long time. Amazingly long.
   Outside of emacs, it took much shorter time.

   #+BEGIN_SRC shell
   find /media/yubrshen/DATA/ai-study -regex ".*\.\(mm\)"
   #+END_SRC

   #+RESULTS:
   | /media/yubrshen/DATA/ai-study/ASimpleNeuralNetworkModuleForRelat.mm                                                             |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/elastic-weight-consolidation/ElasticWeightConsolidation.mm                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/machine-learning-top-level.mm                                                                     |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/Key-Concepts-for-Term-One-of-SDC-ND.mm                                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/session-leader/DevelopmentForUdacitySessionLeader.mm                                          |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/session-leader/FindingStraightLane.mm                                                         |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-Vehicle-Detection/Notes                                                          | on | Project | of                | Vehicle  | Detection  | and | Tracking.mm |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-behavior-cloning/Notes                                                           | on | project | of                | behavior | cloning.mm |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-Traffic-Sign-Classifier-Project/TrafficSignClassificationProject.mm              |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/SDC-term-1-notes.mm                                                                    |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/SystematicEvaluationOfCNNAdvancesOn.mm                                                 |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/vehicle-surrounding/To-brain-storms.mm                                                 |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-2/notes-course/Key-concepts-SDC-term-2.mm                                                |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/notes/scratch.mm                                                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/Capstone-Study/Clarification                                                   | of | stop    | considerations.mm |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/CarND-Capstone/clarify-stop-scenario-algorithm.mm                              |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/CarND-Path-Planning-Project/Development-of-congestion-model-in-traffic-lane.mm |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/ROS_pratcice/ROS-notes.mm                                                      |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/ShenzhenTransportProjectStudy.mm                                                                  |    |         |                   |          |            |     |             |


** Shell scripts know-how

*** cd - change to previous directory

#+BEGIN_SRC shell
pwd
cd ~/tmp
pwd
cd - # expect to /home/yubrshen/programming/tbx-augmented-human-intelligence
cd - # expect to ~/tmp
#+END_SRC

#+RESULTS:
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |

*** cd ~- and cd ~+

~- as a general expression for the previous directory
~+ as the current directory

#+BEGIN_SRC shell
  echo ~+                         # equivalent to pwd: /home/yubrshen/programming/tbx-augmented-human-intelligence
  cd ~/tmp
  echo ~-                         # show the previous directory: /home/yubrshen/programming/tbx-augmented-human-intelligence
  echo ~+                         # pwd: /home/yubrshen/tmp
  cd /tmp
  echo ~+                         # pwd: /tmp
  echo ~- # previous directory: /home/yubrshen/tmp
#+END_SRC

#+RESULTS:
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |
| /tmp                                                        |
| /home/yubrshen/tmp                                          |

*** Difference between cd - and cd - > /dev/null
 > /dev/null suppress output

#+BEGIN_SRC shell
cd ~/tmp
cd -
#+END_SRC

#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence

#+BEGIN_SRC shell
cd - > /dev/null
#+END_SRC

#+RESULTS:

*** Meaning of && in shell commands

Continue, sequential execution

#+BEGIN_SRC shell
echo "Wish you" && echo " Happy New Year!"
#+END_SRC

#+RESULTS:
| Wish  | you |       |
| Happy | New | Year! |

*** pwd and pwd -P

#+BEGIN_SRC shell
pwd
#+END_SRC

with -P just treat symbolic as ordinary path
#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence
#+BEGIN_SRC shell
pwd -P
#+END_SRC
with -P translate symbolic link into physical file
#+RESULTS:
: /media/yubrshen/DATA/programming/tbx-augmented-human-intelligence

*** Putting command outcome to an variable

#+BEGIN_SRC shell
  date=`date`
  echo $date
#+END_SRC

#+RESULTS:
: Sat Dec 30 15:39:30 PST 2017

The same as above to collect output of command:
#+BEGIN_SRC shell
data="$(date)"
echo $data
#+END_SRC

#+RESULTS:
: Sat Dec 30 18:04:25 PST 2017

Create a test script to show the meaning of $0
$0 is the full path of the script.

#+BEGIN_SRC shell
echo 'echo "here is the  full path of script: " "$0"  ' > ~/tmp/tmp.sh
echo 'echo "and here is the folder of the script: " "$(dirname "$0")"' >> ~/tmp/tmp.sh
chmod u+x ~/tmp/tmp.sh
~/tmp/tmp.sh
#+END_SRC

#+RESULTS:
| here | is   | the | full | path   | of | script: | /home/yubrshen/tmp/tmp.sh |                    |
| and  | here | is  | the  | folder | of | the     | script:                   | /home/yubrshen/tmp |

Putting the pieces together:

1. Extract the folder of the path.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(dirname $A_FULL_PATH)"
echo $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |
| /home/yubrshen/tmp        |

2. Use the extracted folder to change into that folder.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)")"
echo "THIS_DIR: " $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |
| THIS_DIR:                 |

1. Then capture the folder path from pwd -P
This would provide the absolute path throug pwd -P, but "$(dirname "$0")" would only provide the relative path
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P)"
echo "THIS_DIR: " $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |                    |
| THIS_DIR:                 | /home/yubrshen/tmp |

4. Then change back to the previous folder before changing into the folder.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
echo "THIS_DIR: " $THIS_DIR
pwd
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh                                   |                    |
| THIS_DIR:                                                   | /home/yubrshen/tmp |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |                    |

5. Use the captured folder name to construct a file path
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
echo "THIS_DIR: " $THIS_DIR
USER_PROFILE="$THIS_DIR/profile.tmp"
echo $USER_PROFILE
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |
| THIS_DIR:                      | /home/yubrshen/tmp |
| /home/yubrshen/tmp/profile.tmp |                    |

6. Check the existence of the file

#+BEGIN_SRC shell
  A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
  echo $A_FULL_PATH
  THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
  echo "THIS_DIR: " $THIS_DIR
  USER_PROFILE="$THIS_DIR/profile.tmp"
  echo $USER_PROFILE
  if [ ! -f "$USER_PROFILE" ];
     then
     echo "What is the full path to your Unity simulator?"
  fi
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |     |      |      |    |      |       |            |
| THIS_DIR:                      | /home/yubrshen/tmp |     |      |      |    |      |       |            |
| /home/yubrshen/tmp/profile.tmp |                    |     |      |      |    |      |       |            |
| What                           | is                 | the | full | path | to | your | Unity | simulator? |

7. Read from terminal from user input
#+BEGIN_SRC shell
  A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
  echo $A_FULL_PATH
  THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
  echo "THIS_DIR: " $THIS_DIR
  USER_PROFILE="$THIS_DIR/profile.tmp"
  echo $USER_PROFILE
  if [ ! -f "$USER_PROFILE" ];
     then
     echo "What is the full path to your Unity simulator?"
     read unity_path
     echo $unity_path
  fi
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |     |      |      |    |      |       |            |
| THIS_DIR:                      | /home/yubrshen/tmp |     |      |      |    |      |       |            |
| /home/yubrshen/tmp/profile.tmp |                    |     |      |      |    |      |       |            |
| What                           | is                 | the | full | path | to | your | Unity | simulator? |
|                                |                    |     |      |      |    |      |       |            |

As I don't know how to execute the shell with input, the following script needs to be executed at a terminal prompt to test.

#+BEGIN_SRC shell
  echo 'echo "Please input your name:"' > ~/tmp/prompt-input-tmp.sh
  echo 'read name' >> ~/tmp/prompt-input-tmp.sh
  echo 'echo $name' >> ~/tmp/prompt-input-tmp.sh
  chmod u+x ~/tmp/prompt-input-tmp.sh
  ls -lt ~/tmp/prompt-input-tmp.sh
  # cat ~/tmp/prompt-input-tmp.sh
  script=$(cat ~/tmp/prompt-input-tmp.sh)
  echo $script
#+END_SRC

#+RESULTS:

By executing the generated the script, here is the trace of the execution:

#+BEGIN_QUOTE
$ ~/tmp/prompt-input-tmp.sh
Please input your name:
Jonah
Jonah
#+END_QUOTE

Get one line of content from a file to a variable

#+BEGIN_SRC shell
  script=$(cat ~/tmp/prompt-input-tmp.sh)
  echo $script
#+END_SRC

#+RESULTS:
: Please input your name:

*** bash: the last argument of the previous command !$

 #+BEGIN_SRC shell
#!/usr/bash
echo "Hello"
echo !$
 #+END_SRC

 #+RESULTS:
 | Hello |
 | !$    |


** Effective with git (github)

*** To be able to access new branches in remote repository that I have cloned from

    It takes the following:

 #+BEGIN_SRC shell
 git pull
 #+END_SRC
 at a any current branch, to get the meta data of the new branches

*** To access remote branch

 #+BEGIN_SRC shell
 git checkout <path-of-a-branch>
 #+END_SRC
 for example, the path-of-a-branch may origin/tl_detector_sj

*** To set tracking branch with the remote branch

 #+BEGIN_SRC shell
 git branch --set-upstream-to=origin/tl_detector_sj merge-from-tl-detector-sj
 #+END_SRC

 tl_detector_sj is the name of the remote branch.
 merge-from-tl-detector-sj is the name of the local branch corresponding

*** Adding a local existing project to GitHub

1. Create a new repository on GitHub. ...
2. Open TerminalTerminalGit Bash.
3. Change the current working directory to your local project.
4. Initialize the local directory as a Git repository. ...
5. Add the files in your new local repository. ...
6. Commit the files that you've staged in your local repository.
7. Execute a script at the directory of the project to be added, for example, add-new-repository predict-stop-sign-slant-angle

   The script add-new-repository is written by me. It takes an argument of the
   name of the repository newly created on GitHub.

*** Access github without username and password

    The key is to define the remote origin in the fashion working with ssh.
    One can follow this: [[https://gist.github.com/developius/c81f021eb5c5916013dc][Set up GitHub push with SSH keys]]

    The key is to have the following:

    git remote set-url origin git@github.com:username/your-repository.git

    then one can do git pull and git push without being bothered by prompts of username and password.

    However, once with ssh set up, actually even the correct username/password would not work, thus
    one has to use ssh!


*** Shell script to add to a new github repository

  The following script performs the initial upload of a local repository to a newly created github repository.
  The resulted script is in "~/bin/add-new-repository"

  The script's execution permission need to be changed after tangled.

  #+BEGIN_SRC sh
     chmod 704 ~/bin/add-new-repository
  #+END_SRC

  The following is an example of the execution.
  #+BEGIN_SRC sh
     add-new-repository write-slides-with-jupyter
  #+END_SRC

  It must have one argument of the name of the repository.

  #+NAME:add-new-repository
  #+BEGIN_SRC python :noweb yes :tangle ~/bin/add-new-repository :exports none
     #!/home/yubrshen/miniconda3/bin/python
     from subprocess import call
     import sys
     #git remote set-url origin git@github.com:yubrshen/write-slides-with-jupyter.git
     #git remote add origin git@github.com:yubrshen/write-slides-with-jupyter.git
     user_host = "git@github.com:yubrshen/"
     url = user_host + sys.argv[1] + ".git"
     #action = "set-url"
     action = "add" # for initial setup origin url
     call(["git", "remote", action, "origin", url])  # this works!
     call(["git", "push", "origin", "master"])
  #+END_SRC

  Note: to have the command line arguments working, each parameter separated by space
  must be a separated element in the array.

*** Shell script to clone a repository with ssh setup
  The following script performs git clone a repository but with ssh setup for the repository.
  The resulted script is in "~/bin/git-clone-with-ssh"

  The script's execution permission need to be changed after tangled.

  #+BEGIN_SRC sh
     chmod 704 ~/bin/git-clone-with-ssh
  #+END_SRC

  The following is an example of the execution.
  #+BEGIN_SRC sh
   git-clone-with-ssh CarND-Path-Planning-Project
  #+END_SRC

  It must have one argument of the name of the repository.

  #+NAME:git-clone-with-ssh
  #+BEGIN_SRC python :noweb yes :tangle ~/bin/git-clone-with-ssh :exports none
     #!/home/yubrshen/miniconda3/bin/python
     from subprocess import call
     import sys
     import os
     # git clone git://github.com/username/your-repository
     repository = "git://github.com/yubrshen/" + sys.argv[1]
     call(["git", "clone", repository])
     os.chdir(sys.argv[1])
     user_host = "git@github.com:yubrshen/"
     url = user_host + sys.argv[1] + ".git"
     # git remote set-url origin git@github.com:username/your-repository.git
     call(["git", "remote", "set-url", "origin", url])
  #+END_SRC

*** Typical merge to remote branch

 Step 1: From your project repository, bring in the changes and test.

 git fetch origin
 git checkout -b hector-dev origin/hector-dev
 git merge aaron-dev

 Step 2: Merge the changes and update on GitHub.

 git checkout aaron-dev
 git merge --no-ff hector-dev
 git push origin aaron-dev

*** Merge with upstream

 The upstream can be the repository from which my repository is forked from.

 Let's define it and name it (udacity):

 #+BEGIN_SRC shell
 git remote add udacity https://github.com/user/repo.git
 #+END_SRC

 To merge modifications from udacity:

 #+BEGIN_SRC shell
 git fetch udacity
 git merge udacity/merge
 #+END_SRC

** Effective writing slides

 As of Aug., 2017, my choice of slide writing is jupyter notebook with reveal.js,
 for details, here is the tutorial on how to get started quickly.

 https://github.com/yubrshen/write-slides-with-jupyter

** Effective with Emacs

*** Set to variable that is yet to be loaded (defined)

#+NAME:
#+BEGIN_SRC emacs-lisp
(with-eval-after-load 'anaconda-mode
    (add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/sandbox")
    (add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/")
    )
#+END_SRC

python-shell-extra-pythonpaths is defined in anaconda-mode, just doing
(add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/sandbox")
would resulting "Symbol’s value as variable is void: python-shell-extra-pythonpaths" as anaconda-mode has not been loaded.

But use the above expression, it will execute the operation after anaconda-mode is loaded.

*** Disable undersore-to-subscript in org-mode export
    Have the option in the org-mode file:
    #+OPTIONS: ^:nil

    ref: https://stackoverflow.com/questions/698562/disabling-underscore-to-subscript-in-emacs-org-mode-export
*** Understanding of org-mode's option syntax

    #+OPTIONS: ^:nil

    "#+OPTIONS:" indicate the option section
    "^:" for the option property name for subscript/supperscript
    "nil" the value to nil

*** Proper use of company mode's auto-completions
    When typing text, company mode would provide suggestions, use "TAB" key to cycle through the options.

    This is the most effective way. My former way of use "Alt-n" is too cumbersome.

*** Using CDLaTeX to enter math in org-mode

    1. In org-mode, many latex environment delimiters are recognized, and treated the text following the delimiters as latex-environment. The delimiters include
       1. Environments of any kind. The only requirement is that the \begin statement appears on a new line, at the beginning of the line or after whitespaces only.
       2. Text within the usual LaTeX math delimiters.
          To avoid conflicts with currency specifications,
          single ‘$’ characters are only recognized as math delimiters if the enclosed text contains at most two line breaks,
          is directly attached to the ‘$’ characters with no whitespace in between, and
          if the closing ‘$’ is followed by whitespace or punctuation
          (parentheses and quotes are considered to be punctuation in this context).
          For the other delimiters, there is no such restriction, so when in doubt, use ‘\(...\)’ as inline math delimiters.
    http://orgmode.org/manual/LaTeX-fragments.html#LaTeX-fragments

    2. In the latex-environment, cdlatex minor mode can be used, by: (add-hook 'org-mode-hook 'turn-on-org-cdlatex)
       1. Environment templates can be inserted with C-c {.

       2. The <TAB> key will do template expansion if the cursor is inside a LaTeX fragment1.
       For example, <TAB> will expand fr to \frac{}{} and position the cursor correctly inside the first brace.
       Another <TAB> will get you into the second brace.
       Even outside fragments, <TAB> will expand environment abbreviations at the beginning of a line.
       For example, if you write ‘equ’ at the beginning of a line and press <TAB>,
       this abbreviation will be expanded to an equation environment.
       To get a list of all abbreviations, type M-x cdlatex-command-help RET.

       1. Pressing _ and ^ inside a LaTeX fragment will insert these characters together with a pair of braces.
       If you use <TAB> to move out of the braces, and if the braces surround only a single character or macro,
       they are removed again (depending on the variable cdlatex-simplify-sub-super-scripts).

       1. Pressing the grave accent ` followed by a character inserts math macros,
       also outside LaTeX fragments. If you wait more than 1.5 seconds after the grave accent, a help window will pop up.

       1. Pressing the apostrophe ' followed by another character modifies the symbol before point with an accent or a font.
       If you wait more than 1.5 seconds after the apostrophe, a help window will pop up.
       Character modification will work only inside LaTeX fragments; outside the quote is normal.
       http://orgmode.org/manual/CDLaTeX-mode.html#CDLaTeX-mode

*** Effective navigation
    http://ergoemacs.org/emacs/emacs_navigate_lisp_code.html
**** Jump to the enclosing form or function in emacs-lisp code
     - Use backward-up-list Ctrl-Alt + u Move to parent (move to the (beginning of) outer paren pair)
**** Move to the first child
     - down-list

**** Move to next sibling
     - forward-sexp
**** Move to previous sibling
     - backward-sexp

*** Define an emacs lisp function and bind it to a key in a major mode (work-flow)
    1. Define the function: the crucial factor is to call (interactive) at the beginning of the function body.
       For example,
       #+NAME:
       #+BEGIN_SRC emacs-lisp
         (defun my-try-cdlatex-tab ()
           "Call org-try-cdlatex-tab interactively"
           (interactive)
           (org-try-cdlatex-tab))
       #+END_SRC

    2. Bind the function to a key binding in the designated major mode, manually
       To bind a key just in the current major mode, type M-x local-set-key <RET> key cmd <RET>.
       To bind a key to globally, type M-x global-set-key <RET> key cmd <RET>

    3. Recover the key binding code and put them into code file
       To make the process of binding keys interactively easier, use the following “trick”: First bind the key interactively, then
       immediately type C-x <ESC> <ESC> C-a C-k C-g. Now, the command needed to bind the key is in the kill ring, and can be yanked into your file

    4. Embed the code of local-set-key into the designated major mode hook, e.g.

      #+NAME:
      #+BEGIN_SRC emacs-lisp
        (add-hook 'org-mode-hook
                  (lambda ()
                    (local-set-key [C-S-iso-lefttab] (quote my-try-cdlatex-tab))))
      #+END_SRC
      Ref: https://www.gnu.org/software/emacs/manual/html_node/efaq/Binding-keys-to-commands.html

*** Insert figure into org file

    Use the following code to insert a figure.

 #+BEGIN_EXAMPLE
 #+CAPTION: This is the caption for the next figure link (or table)
 #+NAME:   fig:SED-HR4049
 [[./img/a.jpg]]
 #+END_EXAMPLE

 Note the figure might be captured through screenshot!


*** Do screenshot and insert the captured

    1. Show the desired image to be captured
    2. In the point of the butter to insert the screenshot, excute M-x org-download-screenshot
    3. Use the appearing mouse cross-hair pointer to select the screen area to
       be captured.

       Here is an example:


#+DOWNLOADED: /tmp/screenshot.png @ 2018-02-20 11:46:40
[[file:Handy software engineering/screenshot_2018-02-20_11-46-40.png]]


*** Permanently, and globally change the margin of org export to PDF

    (setq org-latex-packages-alist '(("margin=2cm" "geometry" nil)))
    or
    #+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}

*** Write special character/symbol in org-mode
    Use command org-entities-help to find the org entity for the symbol, and
    use {} to seperate the symbol from the rest of the normal character without space in between.

    For example, =p\egrave{}re= for p\egrave{}re

*** Insists on creating new file with helm

    With helm, when accessing new file, if helm does not find any file with name containing the type substrings, then it will create one, no problem.

    But when helm found existing file's name contains the typed as substrings, by default, it will open that the matched file. But one can insist on
    creating the new file by selecting the selected file name by typing C-P, the one above the matched existing file name.

*** Retrieve last command executed

 last-command and this-command

 Normally, whenever a function is executed, Emacs
 sets the value of this-command to the function being executed.
 At the same time, Emacs sets the value of last-command to the previous value of this-command.

*** Debug in emacs
    Use realgud (M-x realgud:pdb, etc. for different language's debugger)
    With spacemacs, the keybindings of function keys are working
    f9 set break point
    mouse click on the beginning of the line where there is a breakpoint: clear the breakpoint
    f10 next
    f11, SPC, Step

    f5: continue
    S-F5: quit

    Some keybindings may not work for spacemacs

    One can also use the associated command buffer to control the debugger. Overall, it's better than using gdb, and gdbtui in Ubuntu.

    https://github.com/realgud/realgud

    As of 2017/9/6, realgud should replace my use of gdbtui on Ubuntu.



*** Mark and point

    When not in transient-mark-mode, with C-x C-x, it's possible to jump between mark and point. It's quite handy
    for situation when one pastes large chunks of text, and then would like to go back to the point at the beginning
    of the pasting. Here are the procedure:
    1. Pre-condition, transient-mark-mode disabled
    2. Set mark at the point for pasting, before the pasting action
    3. Perform the paste operation
    4. Switch between point and mark by command C-x C-x

**** How to disable transient-mark-mode

     A few options:
     - M-x transient-mark-mode to toggle the transient-mark-mode
     - or execute (transient-mark-mode 0) in configuration

**** Temporarily enable transient-mark-mode

     By command C-u C-x C-x (in spacemacs, SPACE u C-x C-x, can temporarily enable the transient-mark-mode

*** Read and make notes with PDF: interleave

    1. Create a new org file
    2. In it, put the line
 #+INTERLEAVE_PDF: <path-to-the-pdf-file>

 then start to read PDF with command M-x interleave

*** Execute shell command and place output to replace the content of the region, in spacemacs

    1. Select the region to be processed and replaced
    2. SPACE u M-! <cmd>

    SPACE u is for universal argument to replace the selected region.

*** Way to let Python live code work with particular environment:
    start the environment in a shell, and start emacs from the shell


*** Indent-region: format a region to have proper indent
    Select the region needing to reformat, then indent-region
    C-M \

*** recursive grep in a directory

    M-x rgrep

    Alternatively, (not really explored, not needed beyond rgrep).

 Use helm-projectile-grep/ack/ag: You can search for everything starting from project root. Later if you want to save the search results, press F3 or press TAB to switch to action menu and select the 3rd action. To navigate hgrep buffer:
 C-<down>: go to next match and open the match.
 C-<up>: go to previous match and open the match.
 M-<down>: go to next match without opening the match.
 M-<up>: go to next match without opening the match.
 C-o: open current match in other window.
 RET: open current match in current window.
 Use helm-projectile-find-dir (note the helm prefix; you must use proper Helm commands from helm-projectile package in general): narrow to a desired directory and press C-u C-s to recursively search in that directory. If you don't press C-u, it just searches in that directory without going deeper.

*** Unbind undo-key u

  #+NAME:unbind-undo-key-u
  #+BEGIN_SRC emacs-lisp
  (unbind-key (kbd "u") evil-normal-state-map)
  #+END_SRC

  #+RESULTS: unbind-undo-key-u

  It works that the key is no longer bound for undo

  Now the new undo key is C-_

*** make the CAPSLOCKS key as ctrl-key in Ubuntu (X-system)

    In order to prevent repetitive injury syndrom (RSI) of hands with keyboard,
    especially emacs-pinky finger injury.

 setxkbmap -layout us -option ctrl:nocaps
 https://askubuntu.com/questions/33774/how-do-i-remap-the-caps-lock-and-ctrl-keys

 Here is some command that it might be useful. (It's pasetd at the wrong place.
 I don't know if it's still useful.)

setxkbmap -device 15 us

*** Don't run long running application from emacs babel code block, it might block emacs itself.

 - such as running a video player, etc.

*** Stop evaluation of code blocks at the export

 Put it at the top of the org file,
 #+BIND: org-export-use-babel nil
 apply it by C-c C-c
 it works!

 The following does not work for me with emacs 25:

 Place the following at the top of the org file, as per file variable:
 # -*- org-export-babel-evaluate: nil -*-

*** Solve the problem of not able to execute code block in org-mode

    Sometimes, after upgrading emacs packages (probably some org-contrib packages, it would no longer
possible to execute code block with C-c C-c it would have the error of: "evaluation of code-blocks is disabled"

The current solution is to execute M-x spacemacs/recompile-elpa after an upgrade, it took a long time, but it
indeed solved the problem.

IT IS A GOOD PRACTICE TO RECOMPILE THE EMACS FILES by M-x spacemacs/recompile-elpa


*** Example of typesetting multiline equation with big brackets
Actually, a better example, would be:
\begin{eqnarray}
\label{eq:1}
 &  & \\
\end{eqnarray

\begin{equation*}\label{eq:lda}
\begin{aligned}
p(W_{d,n}, Z_{d,n}, for \ n \in \{1, \dots, N \},
\theta_d, for \ d \in \{1, \dots, D \},
\beta_k, for \ k \in \{1, \dots, K \}, \alpha, \eta) = \\
\left( \prod_{d=1}^D p(\theta_d | \alpha)
\left( \prod_{n=1}^N p(Z_{d,n} | \theta_d) p(W_{d,n} | Z_{d,n}, \beta_1, \dots, \beta_K) \right)
 \right)
\bigg(\prod_{k=1}^K p(\beta_k | \eta)\bigg)
\end{aligned}
\end{equation*}

*** To prevent linked files from being embedded of org-mode file when exported to PDF

    Use C-u C-c C-l (or Space u C-c C-l in spacemacs) with non-empty
    description.


*** To have org-capture to place the todo's into a specific files, one has to set the proper value of org-default-notes-file,
    otherwise, the system might place new notes.org in the current directory
    where the capture was happening. I explicitly set the following:
    #+BEGIN_SRC emacs-lisp
(setq org-directory "~/zoom-out")
(setq org-default-notes-file (os-path (concat org-directory "/" "notes.org")))
    #+END_SRC
    It works.

*** To have todo items showing up in the org agenda view, the value of org-agenda must be properly set.
    The org file that contains those todo items must be in the list as the value
    to org-agenda.

    Currently, the following works:
    #+BEGIN_SRC emacs-lisp
    (setq org-agenda-files (list org-default-notes-file
                             (os-path "~/Dropbox/schedule.org")))
    #+END_SRC


*** Proper value of :noweb in org-babel

    I ran into situation when use the value of tangle for :noweb when the code
    block is nested in the third level, the code block was not tangled in the
    source code. But using yes as value, then the problem is gone.

    It seems that this is a bug. That I should report.

    So the moral of the story is that use I should use no-export instead of
    tangle to achieve my desired effect: to tangle and evaluate, but do not
    export.

    Here is the relevant document:
    https://orgmode.org/manual/noweb.html
    no Default. No expansion of Noweb syntax references in the body of the code when evaluating, tangling, or exporting.
    yes Expansion of Noweb syntax references in the body of the ‘src’ code block when evaluating, tangling, or exporting.
    tangle Expansion of Noweb syntax references in the body of the ‘src’ code block when tangling. No expansion when evaluating or exporting.
    no-export Expansion of Noweb syntax references in the body of the ‘src’ code block when evaluating or tangling. No expansion when exporting.
    strip-export Expansion of Noweb syntax references in the body of the ‘src’ code block when expanding prior to evaluating or tangling. Removes Noweb syntax references when exporting.
    eval Expansion of Noweb syntax references in the body of the ‘src’ code block only before evaluating.


*** How to add additional packages with modern_emacs setup with spacemacs

    There are two ways to do it:
    1. Add in the file .spacemacs.d/init.el in the list of packages for
       spacemacs-additional-packages. This only works for package that does not
       require any configuration.
    2. For package requiring configuration, it can be added in
       .spacemacs.d/layers/config/packages.el put the new package in the list
       for the value of config-packages, and then provide the function to
       configure the new package in terms of
       #+BEGIN_SRC emacs-lisp
(defun config/init-<package-name>-config ()
  (use-package <package-name>
    :after <dependency>
    :init (progrn
           )
    :config (progn
              )))
       #+END_SRC


*** Address the error message of "Evaluation of code disabled" when C-C-c executing code in org-mode

    With spacemacs, after upgrading packages, this may happen. The solution is
    to execute M-x spacemacs/recompile-elpa

    Only compile ob-core.el didn't help.

    For details, see here:
    https://github.com/syl20bnr/spacemacs/issues/7641


*** Search string in a whole directory: <space>/

    This will show all the line with the text searched.

** Effective with web browsing

*** Cycle through tabs in Chrome browser

    Ctrl+SHIFT+TAB

*** Switch to previous tab in Chrome browser
    Allt+w (with a plugging installed)

** Effective in programming

*** How to read program effectively?

    - Start with the first entry of the program, follow through the implementation of the top level functions in the entry implementation

    - Follow along the paths of the implementation until comfortable to comprehension.

    - This may ignore all the other code not along the main call paths

    - Make notes of the domain model of the program while tracking the code paths

*** Programming: Promptly and early return: a way to simplify if then else enclosing hierarchy:

  The following code illustrates the technique to reduce excessive levels of if else enclosing. The alternative
  would have been use if then else all the way.

  The pros of this approach is that the code would be shorter.

  The cons is that when the code is indeed long, the context of the logic ("else" assumption would be lost, hard to read the code.)
  For this context, needs comment to remind the fact.

  That is, use comment to replace the else statement.
  #+NAME:
  #+BEGIN_SRC python :noweb tangle :tangle
   # triangle(a, b, c) analyzes the lengths of the sides of a triangle
   # (represented by a, b and c) and returns the type of triangle.
   #
   # It returns:
   #   'equilateral'  if all sides are equal
   #   'isosceles'    if exactly 2 sides are equal
   #   'scalene'      if no sides are equal
   #
   # The tests for this method can be found in
   #   about_triangle_project.py
   # and
   #   about_triangle_project_2.py
   #
   def triangle(a, b, c):
       def test_two_sides(a, b, c):
           if ((a + b) <= c):
               raise(TriangleError)

           if (a == b):            # already legal sides
               if (c == a):
                   return 'equilateral'
               else:
                   return 'isosceles'
           else:
               return None
       if (a <= 0) or (b <= 0) or (c <= 0):
           raise(TriangleError)
       # below all sides are positive now
       result = test_two_sides(a, b, c) or test_two_sides(a, c, b) or test_two_sides(b, c, a)
       return result if result else 'scalene'

   # Error class used in part 2.  No need to change this code.
   class TriangleError(StandardError):
       pass

  #+END_SRC

*** Effective regular expression building and testing

   Here is an effective tool to build and validate regular expression.
   Make sure to select Javascript (not Php) as language to be closer to C++, and others.
j

** Effective use of HackerRank drill page

 1. Copy the description to my editor to help to parse and understanding
 2. Code the required in emacs babel buffer
 3. Paste the coded code to HackerRank's window for the code segment
 4. Excute "Run Code" in HackerRank (as it provides better error visualization)
 5. Fix the code in my own buffer of emacs, repaste
 6. When passing the "Run Code", submit
 7. If there is any failed case, download the test case.
 8. Paste the input to the custom input, while the expected output to emacs's scrath buffer
 9. Run Code to find out the difference between the output  and the expected
 10. Only as last resort, copy all the code including main to emacs buffer and run the tests locally.


** The understanding of "leap" year, a challenge in HackerRank

In the Gregorian calendar three criteria must be taken into account to identify leap years:

1. The year can be evenly divided by 4, is a leap year, unless:
2. The year can be evenly divided by 100, it is NOT a leap year, unless:
3. The year is also evenly divisible by 400. Then it is a leap year.

This means that in the Gregorian calendar, the years 2000 and 2400, 1992 are leap
years,
while 1800, 1900, 2100, 2200, 2300 and 2500 are NOT leap years.

The rules can be simplified as follows:
1. Divisible by 400, or
2. Not divisible by 100, but by 4.

The above rules are designed to add approximately appropriate days to compensate
that the actual a year's length is 365.245 days. For the scale of 10,000 years,
the above rules would nearly compensate the missing 0.245 days * 10,000 years =
2450 days.

It's tricky to interpret the meaning. The following implementation is correct.
#+NAME:leap-year
#+BEGIN_SRC python :noweb no-export :tangle
leap = ((((year % 4) == 0) and (year % 100 != 0))
        # divisible by 4 unless divisible by 100
        or
        (((year % 4) == 0) and ((year % 400) == 0)))
        # divisible by 4 and divisible by 400 (of course divisible by 100)
#+END_SRC


** Effective in shell


*** Invoke command when a file or folder changes

 #+BEGIN_SRC shell
 when-changed file-or-folder-monitor-for-change <command-as-usual>
 #+END_SRC

 Here is the repository for when-changed to install:
 https://github.com/joh/when-changed

*** Positional shell command arguments
  If some_program were a bash shell script, we could read each item on the command line because the positional parameters contain the following:
  $0 would contain "some_program"
  $1 would contain "word1"
  $2 would contain "word2"
  $3 would contain "word3"

  #+BEGIN_SRC shell :tangle "~/bin/vedio-play.sh"
   #!/bin/bash
   # this is the command to view a *.mov file, working in Ubuntu 16.04
   mplayer -vo vdpau $1 # ~/tmp/potential_bug.mov
  #+END_SRC


*** Capture shell output to a file

  Sometimes just redirect the standard output may not work. I don't know why.

  #+BEGIN_SRC shell
 rostopic echo /rosout > rosout.log
  #+END_SRC

  But the following seemed working:

  #+BEGIN_SRC shell
 rostopic echo /rosout &>> rosout.log
  #+END_SRC

  This one capture all including standard error, as well as standard output, and it captures by appending.

** Effective with Ubuntu

*** Swap CAPSLOCKS and Esc

 In order to be more effective with vi/emacs (vi-mode), I'd like to use CAPSLOCKS to be escape key.

 The following procedure didn't work, as =/org/gnome/desktop/input-sources/xkb-options $capslock= did not exist.

**** A real successful one

 With emacs, use ,, as the escape key
 #+NAME:keychord-escape
 #+BEGIN_SRC emacs-lisp
 (evil-escape-mode)
 (setq-default evil-escape-key-sequence ",,")
 (setq-default evil-escape-delay 0.3) ; the suggested is 0.2, but to me it's still not enough delay, 0.3 seems better.
 #+END_SRC

 #+RESULTS: keychord-escape
 : 0.3

 ;; The delay between the two key presses can be customized with the variable evil-escape-delay. The default value is 0.1. If your key sequence is composed with the two same characters it is recommended to set the delay to 0.2.

 Note, it only works after a space ' '

**** A failed one

 The following solution is not reliable sometimes it worked, but afterwards, only escape became
 CAPSLOCKS, but CAPSLOCKS didn't function as escape!

 I gave up on this solution, as I have much better one in emacs using evil-escape-mode with keybinding of ,,
 as of<2017-12-11 Mon 09:42>

 According to https://askubuntu.com/questions/363346/how-to-permanently-switch-caps-lock-and-esc

 Another way to do this is through the dconf-editor. This method has a few extra steps from gnome-tweak-tool, but is useful if you don't want to pull in the dependencies from the teak tool.

 This will allow you to use the caps:swapescape syntax and automatically keep the change permanent.

 sudo apt-get install dconf-tools
 After starting the dconf-editor, navigate to org >> gnome >> desktop >> input-sources

 Add the options that you need in xkb-options. The option strings are surrounded by single quotes and separated by commas. Be careful not to delete the brackets on the ends.

 The value to set to xkb-options is 'terminate:ctrl_alt_bksp,caps:swapescape'

 Now, it's working.

**** A failed attempt.
  #+BEGIN_SRC shell
  ls -lt /org/gnome/desktop/input-sources/xkb-options
  #+END_SRC

  #+RESULTS:

   #+BEGIN_SRC shell :tangle ~/bin/swap-caps-esc.sh
   #!/bin/bash

   current=$(dconf read /org/gnome/desktop/input-sources/xkb-optionsy)
   swapped="['caps:swapescape']"
   capslock="['caps:capslock']"
   echo "Current status: $current"

   if [ "$current" == "$swapped" ]
   then
     echo "Making caps and escape WORK NORMALLY"
     dconf write /org/gnome/desktop/input-sources/xkb-options $capslock
   elif [ "$current" == "$capslock" ]
   then
     echo "Swapping caps and escape"
     dconf write /org/gnome/desktop/input-sources/xkb-options $swapped
   else
     echo "caps is not swapescaped nor capslock. Doing nothing."
   fi
   #+END_SRC

   #+BEGIN_SRC shell
   dconf read /org/gnome/desktop/input-sources/xkb-optionsy
   #+END_SRC

   #+RESULTS:

   #+BEGIN_SRC shell
   chmod u+x ~/bin/swap-caps-esc.sh
   #+END_SRC


   #+RESULTS:

*** Remove applications from startup in Ubuntu 16.04

  #+BEGIN_SRC shell
   cd ~/.config/autostart/
   # remove the start up file for the application
   # for example
   mv skypeforlinux.desktop skypeforlinux.desktop.bak
  #+END_SRC


*** Setup for screencast with vokoscreen

  1. To record voice, after click on Audio, must select Pulse and select both Monitor of Built-in Audio Analog Stero, and Built-in Audio Analog Stero
  2. To play back must use OpenShot. Totem nor vlc works. But banshee, and Gnome mplayer work.
  3. For video capture, click on the webcam, muse use the default settings (Frame: 25; Videocodec: libx264; Format: mkv; Audiocodec: libmp3lame
  4. For the position of the video image, one may be able to arrange, but to make the video visible, it must be part of the screen capture area.
** Upgrade freeplane

 After downloading the latest from https://sourceforge.net/projects/freeplane/files/latest/download
 #+BEGIN_SRC shell
   cd ~/bin
   rm freeplane.sh
   ln -s freeplane-1.6.12/freeplane.sh freeplane.sh
 #+END_SRC

 #+RESULTS:

 The version of freeplane-1.6.10 has a problem of latex editor, with misplacement of cursor, when editing node with \latex format.
 The problem is with 1.6.3, .7, 10, 11. The work-around is to edit without \latex first, then after completion, add \latex

 #+RESULTS:

 Verify the update:
 #+BEGIN_SRC shell
 ls -lt ~/bin/freeplane.sh
 #+END_SRC

 #+RESULTS:
 : lrwxrwxrwx 1 yubrshen yubrshen 28 Nov 22 21:02 /home/yubrshen/bin/freeplane.sh -> freeplane-1.6.3/freeplane.sh

** Redirection of command output to files: various options

 To write the output of a command to a file, there are basically 10 commonly used ways.

 Overview:
 Please note that the n.e. in the syntax column means "not existing".
 There is a way, but it's too complicated to fit into the column. You can find a helpful link in the List section about it.

           || visible in terminal ||   visible in file   || existing
   Syntax  ||  StdOut  |  StdErr  ||  StdOut  |  StdErr  ||   file
 ==========++==========+==========++==========+==========++===========
     >     ||    no    |   yes    ||   yes    |    no    || overwrite
     >>    ||    no    |   yes    ||   yes    |    no    ||  append
           ||          |          ||          |          ||
    2>     ||   yes    |    no    ||    no    |   yes    || overwrite
    2>>    ||   yes    |    no    ||    no    |   yes    ||  append
           ||          |          ||          |          ||
    &>     ||    no    |    no    ||   yes    |   yes    || overwrite
    &>>    ||    no    |    no    ||   yes    |   yes    ||  append
           ||          |          ||          |          ||
  | tee    ||   yes    |   yes    ||   yes    |    no    || overwrite
  | tee -a ||   yes    |   yes    ||   yes    |    no    ||  append
           ||          |          ||          |          ||
  n.e. (*) ||   yes    |   yes    ||    no    |   yes    || overwrite
  n.e. (*) ||   yes    |   yes    ||    no    |   yes    ||  append
           ||          |          ||          |          ||
 |& tee    ||   yes    |   yes    ||   yes    |   yes    || overwrite
 |& tee -a ||   yes    |   yes    ||   yes    |   yes    ||  append
 List:
 command > output.txt

 The standard output stream will be redirected to the file only, it will not be visible in the terminal. If the file already exists, it gets overwritten.

 command >> output.txt

 The standard output stream will be redirected to the file only, it will not be visible in the terminal. If the file already exists, the new data will get appended to the end of the file.

 command 2> output.txt

 The standard error stream will be redirected to the file only, it will not be visible in the terminal. If the file already exists, it gets overwritten.

 command 2>> output.txt

 The standard error stream will be redirected to the file only, it will not be visible in the terminal. If the file already exists, the new data will get appended to the end of the file.

 command &> output.txt

 Both the standard output and standard error stream will be redirected to the file only, nothing will be visible in the terminal. If the file already exists, it gets overwritten.

 command &>> output.txt

 Both the standard output and standard error stream will be redirected to the file only, nothing will be visible in the terminal. If the file already exists, the new data will get appended to the end of the file..

 command | tee output.txt

 The standard output stream will be copied to the file, it will still be visible in the terminal. If the file already exists, it gets overwritten.

 command | tee -a output.txt

 The standard output stream will be copied to the file, it will still be visible in the terminal. If the file already exists, the new data will get appended to the end of the file.

 (*)

 Bash has no shorthand syntax that allows piping only StdErr to a second command, which would be needed here in combination with tee again to complete the table. If you really need something like that, please look at "How to pipe stderr, and not stdout?" on Stack Overflow for some ways how this can be done e.g. by swapping streams or using process substitution.

 command |& tee output.txt

 Both the standard output and standard error streams will be copied to the file while still being visible in the terminal. If the file already exists, it gets overwritten.

 command |& tee -a output.txt

 Both the standard output and standard error streams will be copied to the file while still being visible in the terminal. If the file already exists, the new data will get appended to the end of the file.

 shareeditflag
 edited May 23 at 12:39


 Community♦
 1
 answered Feb 8 '16 at 14:52


 Byte Commander
 45.4k19121222
 14

 Thanks for the table, it's excellent! This should be top answer – DevShark Aug 15 '16 at 16:24


 Great information! Can you also add the details of 2>&1 / 1>&2 / 3>&1 ? – karthick87 Sep 19 '16 at 16:30
  	 upvote
 	 flag
 @karthick87 This is not really related to the question about redirecting output to a file, because it just redirects one stream to another. 2>&1 redirects STDERR to STDOUT, 1>&2 redirects STDOUT to STDERR and 3>&1 would redirect stream 3 to STDERR. – Byte Commander Sep 19 '16 at 16:42

** Keyboard improvement

 The problems:

 - Esc key is too far away, not convenient to access. With spacemacs,
 it's used very often. Binding it to ,, works most of the time, but not always.
 (It's a minor problem with ,, bound for esc.)

 - Control key on the left is not convenient to access. It's no longer possible to ctrl-x with one hand with Dvorak keyboard.
 (A potential solution is to use palm to press it.)

 Potential solutions:

 - Esc:
   - bound to CAPSLOCKS
   - bind shift-CAPSLOCKS for CAPSLOCKS
   - bound to ,,
   - bind control to esc

 - Control key
   - use palm to press it
   - use xcape to bind to long press CAPSLOCKS for left control key
   - use xcape to bind to long press Enter for the right control key
   - bind esc to control key

 Map CAPSLOCKS to control and escape both:

 http://tiborsimko.org/capslock-escape-control.html

 #+BEGIN_SRC shell
 # make CapsLock behave like Ctrl:
 setxkbmap -option ctrl:nocaps

 # make short-pressed Ctrl behave like Escape:
 xcape -e 'Control_L=Escape'
 #+END_SRC

 #+RESULTS:

 Troubleshooting
 If the CapsLock key gets "stuck" and produces say uppercase letter combinations instead of lowercase ones,
 the easiest way to remove xcape mapping is to revert CapsLock key function via xmodmap:

 #+BEGIN_SRC shell0
 xmodmap -e 'keycode 0x42 = Caps_Lock'
 #+END_SRC
 followed by re-running of the keyboard modification script.

 More elaborate configuration example:

 #+BEGIN_SRC shell
 # set internal keyboard layout:
 deviceid=$(xinput -list | grep 'AT .* keyboard' | head -1 | grep -oE 'id=[0-9]+' | sed 's/id=//g')
 if [ "${deviceid}" != "" ]; then
     setxkbmap -device "${deviceid}" dvorak
     setxkbmap -device "${deviceid}" -option ctrl:nocaps # make CapsLock behave like Ctrl
 fi

 # set Kinesis keyboard layout:
 for deviceid in $(xinput -list | grep ' HID ' | grep -oE 'id=[0-9]+' | sed 's/id=//g'); do
     if [ "${deviceid}" != "" ]; then
         setxkbmap -device "${deviceid}" us # 'us' but it means 'dvorak' actually due to Kinesis
         setxkbmap -device "${deviceid}" -option ctrl:nocaps # make CapsLock behave like Ctrl
     fi
 done
 #+END_SRC

 #+BEGIN_SRC shell
 deviceid=$(xinput -list | grep 'AT .* keyboard' | head -1 | grep -oE 'id=[0-9]+' | sed 's/id=//g')
 echo $deviceid

 #+END_SRC

 #+RESULTS:
 : 15

IT seems that $variable and ${variable} are equivalent.

#+BEGIN_SRC shell
id=15
echo "Here is id: " $id "and id again: " ${id}
#+END_SRC

#+RESULTS:
: Here is id:  15 and id again:  15

There seems a problem that the keyboard setup by setxkbmap might be lost after suspend.
It's confirmed on the Internet, but no apparent solution has been found.

Let me monitor if the problem happen again.

** Solution to address the lost of keyboard configuration after suspension
https://unix.stackexchange.com/questions/59623/custom-keyboard-layout-is-reset-to-default-after-standby-or-reboot

Check out this archlinux forum thread Xmodmap Reset after Suspend to RAM.
There are several examples in the thread that'll get you started and show you
how to setup a hook
which will get triggered via the power management subsystem that will run your xmodmap setup each time you come out of suspend.

Something like the following script, saved as /etc/pm/sleep.d/11suspend (change
the me in /bin/su - me to your actual username):

# content of /etc/pm/sleep.d/11suspend
#!/bin/bash
case $1 in
    hibernate)
        echo "Hey guy, we are going to suspend to disk!"
        ;;
    suspend)
        echo "Oh, this time we're doing a suspend to RAM. Cool!"
        ;;
    thaw|resume)
        echo "oh, suspend is over, we are in $1 phase..."
            # Set Display #
    DISPLAY=:0.0 ; export DISPLAY
    /bin/su - me -c "sleep 3; /usr/bin/xmodmap /home/me/.xmodmaprc" &
        ;;
    *)  echo "somebody is calling me totally wrong."
        ;;
esac

In the above need to define ~/.Xmodmap may also need to execute some shell
commands to execute xcape commands.

** Effective with Googe Keep

*** Export all Keep notes to Google Doc
https://googlesystem.blogspot.com/2015/08/export-all-your-google-keep-notes.html#gsc.tab=0

** Effective with Google inbox email

*** To out indent in inbox email composition

To out indent, just press two Enter at the indented text!


** I may use the Google's python-fire (https://github.com/google/python-fire)
to ease the workload to convert python libraries into command line tools.



** Dual boot between Windows 10 and Ubuntu 16.04

1. To boot Windows on Alienware 15 R, the setting of SATA needs to set to RAID
   ON. It's achieved by pressing F2 while booting up at the BIOS stage to enter into
   BIOS setup, to perform the setting change of devices.
2. To boot Ubuntu on Alienware 15 R, the setting of SATA needs to set to ACHI.
   It's achieved by pressing F2 while booting up at the BIOS stage to enter into
   BIOS setup, to perform the setting change of devices.

After booting up Windows, it might corrupt the grub boot selection tool, that
it's no longer possible to select to boot Ubuntu grub. This problem may be fixed by
running boot repair tool in Ubuntu.

To run Ubuntu in the above failure situation, there a few options:

a. https://itsfoss.com/no-grub-windows-linux/
1. In Windows, go to the menu
2. Search for Command Prompt, right click on it to run it as administrator.
3. Execute in the command prompt:
#+NAME:
#+BEGIN_SRC shell
bcdedit /set {bootmgr} path \EFI\ubuntu\grubx64.efi
#+END_SRC

Restart and you’ll be welcomed by the familiar Grub screen.
Remember need to change the SATA setting for Ubuntu to be ACHI!

The above procedure works the best.

b. During booting at the BIOS stage, press F12, to select to boot Ubuntu from
the hard disk partition for Ubuntu. This one sometimes does not work.

c. Use a USB Ubuntu drive to boot Ubuntu from the USB drive. But settings should
be made to let the machine first boot from USB device.


** Setup cross-machines file sharing and synchronization

   Through Google drive, setup file backup and synchronization on Windows 10,
   also setup similar on Ubuntu.




** Found a way to do diff for .docx file with git diff

   https://github.com/vigente/gerardus/wiki/Integrate-git-diffs-with-word-docx-files
   Now my Ubuntu has benn set up to do that.

   It's matter of setting ~/.gitconfig etc.

   For details see the above link

   The full text is copied below:

Integrate git diffs with word docx files
Ramón Casero edited this page on Jul 10, 2016 · 5 revisions
 Pages 5
Home
Build instructions
Getting started for new developers
Integrate git diffs with word docx files
Technical programming notes
Clone this wiki locally

https://github.com/vigente/gerardus.wiki.git
See diffs of .docx files with git wdiff file.docx.
This section was inspired by Martin Fenner's "Using Microsoft Word with git".

To configure git diff:

Install pandoc.

Tell git how to handle diffs of .docx files.

Create or edit file ~/.gitconfig (linux, Mac) or "c:\Documents and Settings\user.gitconfig" (Windows) to add

 [diff "pandoc"]
   textconv=pandoc --to=markdown
   prompt = false
 [alias]
   wdiff = diff --word-diff=color --unified=1
In your paper directory, create or edit file .gitattributes (linux, Windows and Mac) to add

 *.docx diff=pandoc
You can commit .gitattributes so that it stays with your paper for use in other computers, but you'll need to edit ~/.gitconfig in every new computer you want to use.

Now you can see a pretty coloured diff with the changes you have made to your .docx file since the last commit

git wdiff file.docx
To see all changes over time

git log -p --word-diff=color file.docx
Track changes in Word (.docx) documents getting a diff with the commit.
Automatically when running git commit.
This is only going to work from linux/Mac or Windows running git from a bash shell.

Install pandoc. Pandoc is a program to convert between different file formats. It's going to allow us to convert Word files (.docx) to Markdown (.md).

Set up git hooks to enable automatic generation and tracking of Markdown copies of .docx files.

Copy these hook files to your git project's .git/hooks directory and rename them, or soft-link to them with ln -s, and make them executable (chmod u+x *.sh):

pre-commit-git-diff-docx.sh -> .git/hooks/pre-commit
post-commit-git-diff-docx.sh -> .git/hooks/post-commit
Now every time you run git commit, the pre-commit hook will automatically run before you see the window to enter the log message. The hook is a script that makes a copy in Markdown format (.md) of every .docx file you are committing. The post-commit hook then amends the commit adding the .md files.

Manually by creating a Markdown copy of the .docx file.
This works in linux, Mac and Windows.

Install pandoc.

Edit your Word document as needed.

Run pandoc from the linux or Windows command line. This will create a Markdown version of your file (without Figures, but with equations in latex format)

 pandoc -s file.docx -t markdown -o file.md
Update the ChangeLog

Commit both files with git

 git add file.docx file.md
 git commit


** Better conversion from pandoc markdown to Word .docx

   Instead of directly converting from markdown to .docx with pandoc

   use latex as the intermediate so that it may convert better the markdown
   format:

   pandoc -f markdown -t latex -o mydoc.tex mydoc.md && \
   pandoc -f latex -t docx --data-dir=docs/rendering/ -o mydoc.docx mydoc.tex

   https://stackoverflow.com/questions/14249811/markdown-to-docx-including-complex-template


** A good site on using pandoc for accademic publishing especially to Word/.docx

   https://jabranham.com/blog/2016/11/using-pandoc-export-to-word/


** Literate devops as a means to be more effective programmer

   This is a good example of doing literate devops with org-mode
http://www.howardism.org/Technical/Emacs/literate-devops.html

I also saw one doing similar literate devops with Jupyter Notebook

I may want to study literate devops to overcome my forgetfulness, and lack of
speed and precision in devops that's necessary for a programmer.


** Be careful when executing code block not seeing error nor outcome in org-modern_emacs

With a code block with a name, the output results is append to the result section for the
same name. If there is duplicated name for another code block, the result will be
stacked together. If the result section is elsewhere in the file, it might appear that
the same named code does not produce output.

For example,

#+NAME:block-A
#+BEGIN_SRC emacs-lisp
(+ 1 2)
#+END_SRC

#+RESULTS: block-A
: HelloWorld!
: 3

#+NAME:block-A
#+BEGIN_SRC emacs-lisp
(concat "Hello" "World!")
#+END_SRC

This might be a way to compose text using code block!

* Handy languages
** Effective C++
*** object assignment need to have default constructor to work

   For object assignment to work, the class for the object must have default constructor, taking no arugment.

*** C++ compiler can provide the copy constructor and assignment operator for call with pointer as member

   Also note, for class without pointer as member, then the copy constructor, and assignment operator can be provided by
   the compiler, no need to code manually, unless there is special requirements in the implementation.

   While with class with pointer as member, then the copy constructor and assignment operator must be manually defined,
   as it matters how "deep" the copy and assignment should be performed along the pointer.

*** #include <algorithm> needed for operator of vector of string
    In the following code,
 vector.erase(std::remove(a_vector.begin(), a_vector.end(), value), a_vector.end());

 it needs to use the special string value comparison defined in algorithm to work.
 without including algorithm, it will use the default, causing the following error:

 #+BEGIN_QUOTE
 error: cannot convert ‘std::vector<std::__cxx11::basic_string<char> >::iterator {aka __gnu_cxx::__normal_iterator<std::__cxx11::basic_string<char>*, std::vector<std::__cxx11::basic_string<char> > >}’
 to ‘const char*’ for argument ‘1’ to ‘int remove(const char*)’
    a_vector.erase(std::remove(a_vector.begin(), a_vector.end(), value), a_vector.end());

 #+END_QUOTE

 without #include <algorithm>, it will also cause the following error:

 #+BEGIN_QUOTE
 In instantiation of
 ‘typename T::iterator min_map_element(T&) [with T = std::map<std::__cxx11::basic_string<char>, float>; typename T::iterator = std::_Rb_tree_iterator<std::pair<const std::__cxx11::basic_string<char>, float> >]’:
 required from here
 error: ‘min_element’ was not declared in this scope
    return min_element(m.begin(), m.end(),

 #+END_QUOTE

*** The lifetime of auto declaration variables (objects) is within the scope where it's declared
    - auto declaration: such as int i;
    - a pair of bracket define a scope
    - a variable declared as auto variable would not have guarantee to exist outside of its declaring scope!

    [[ihttps://stackoverflow.com/questions/11137516/scope-vs-lifetime-of-variabled:][Scope vs. Lifetime of Variable]]

    Also note that Python's scope is much simpler and more generous: only function and global are scopes,
    the other code block is not scope, thus has no impact to the lifetime of Python object

*** The lifetime of returned value
    The return value from a function is temporary only guarantee to exist during the statement of calling the function.
    Therefore the returned value should be assigned to an variable in order to extend or preserve the lifetime of the returned value.

*** Enable core dump generation in Ubuntu

    On terminal to execute the following:
 #+BEGIN_SRC sh
 ulimit -c unlimited
  #+END_SRC

 to have it permanent, put the command in ~/.profile

*** Investigation of core dump file

    gdb <executable> ./core

*** To manipulate a vector as value keyed in a std::map

    The address of the vector (pointer) instead of vector value must be used. Otherwise, it would not be the same vector, but a new instance
    of empty vector.

    Anything on the left hand-side or target of manipulation, must use pointer to the address, cannot be the value.

    Note, to express a map from string to vector pointer should be as following:
    map<string, vector<double>* > // not map<string, *vector<double> >

*** Effective C++/C debug

    As of 2017/9/6, see realgud entry: [[Debug in emacs]], as it's more user friendly than gdbtui.

    Use gdbtui (GDB with GUI):
    gdbtui <path-to-executable>

    To enable cmake to setup for debug, use cmake-gui, select build type as Debug, then make on the command line.

    Major command in GDB:
    break <line number>
    run to run the loaded program
    continue to resume from breakpoint

    display <variable-name> to auto show the value of the variable
    print <variable-name> to show the value of the variable once; print *<pointer> (to show the data pointed by the pointer)

    undisplay to remove all previously displayed variables.

**** Passing arguments and rediction from standard input still works inside gdbtui

  Pass the arguments to the run command from within gdb.

  $ gdb ./a.out
  (gdb) r arg1 arg2 < t
  Starting program: /dir/a.out < t

**** Typical workflow with GDB

     1. Make
     2. gdbtui <executable>
     3. break <all interested line numbers>
     4. r arg1 arg2 < <input_in_file>
     5. examine at a breakpoint
     6. continue, repeat step 5 (the previous)

**** Running C++ program interactive with emacs/ubuntu
     There are a few options:
     1. Use cpp.sh (a web site, paste code to the code window and run). Note: when there is some crash, it may not report the error, such as segmentation fault, etc.
     2. Use my own sandbox mechanism of tangle to ~/programming/cplusplus/sandbox/src/sandbox.cpp and run in command shell (Note, the command to tangle in spacemacs is <SPACE> u C-v C-t t, not to confusing with u without <SPACE> which is undo!
     3. Use emacs org-babel executing code block, see https://emacs.stackexchange.com/questions/15065/org-mode-babel-interactive-code-block-evaluation
     4. Use Jupyter C++ kernel, see http://shuvomoy.github.io/blog/programming/2016/08/04/Cpp-kernel-for-Jupyter.html for leads

**** There is a way to construct vector literals in C++
     For example,
     vector<int> a_vector = {1, 2, 3} // This requires C++11
      There might be way to use << operation, such as
      vector<string> a_vector;
      a_vector << "Hello" << "World"; // not verified.

      Another to do it is via array initialization

  static const int arr[] = {16,2,77,29};
  vector<int> vec (arr, arr + sizeof(arr) / sizeof(arr[0]) );


**** It's complicated to find length of a C++ array, use vector instead

     int a[7];
     std::cout << "Length of array = " << (sizeof(a)/sizeof(*a)) << std::endl;

**** Use for (auto x:sequence) { <access code>}
     To traverse the sequence, to avoid confusion and mistakes with iteration variable.

**** Use C++11 for new and improved expressiveness

**** With spacemacs, I found M-x gdb works for C++ debugging

     - To set breakpoint C-x C-a C-b in a source code buffer
     - To clear a breakpoint at the place of the breakpoint, C-x C-a C-d
     - Restore multiple window layout:
  If you ever change the window layout, you can restore the many-windows layout by typing M-x gdb-restore-windows . To toggle between the many windows layout and a simple layout with just the GUD interaction buffer and a source file, type M-x gdb-many-windows .
  GDB User Interface Layout - GNU Emacs Manual - GNU.org
  https://www.gnu.org/software/emacs/manual/.../emacs/GDB-User-Interface-Layout.html

  - running again will automatically reload the updated binary.

**** Build debug enabled executable from C++ source
   at the root of the project:

   cmake -DCMAKE_BUILD_TYPE=Debug build


** Effective Python

*** Use python-live-mode in emacs to visualize the execution

    In the python-live-mode, all value assigned to a variable/label would be shown it's value at the moment of label reference.
    It makes it quite clean of the program execution in terms of value changes.

    python-live-mode can be started by keys 'l in python-mode in spacemacs.

*** Avoid the trap of Python variable assignment

 deepcopy needed to copy multi-dimension list,
 Python's variable is just a label to data value.
 For container type such as list, the assignment only adds one more label for the variable on the right side of assignment to the data value referred by the variable on the left side of the assignment!
 Thus modifying using the either label would cause the same data value (container) to be modified!

 The solution is use copy for one-dimensional list, or full list slicing [:]

 For multiple dimension list, one has to use deepcopy to make actual data duplication.

 It helps to refresh to the understanding of label semantics of Python variable:  http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html#python-has-names

 Here is examples to illustrate the problems and solutions:

 In the examples, I assume using python live-mode in emacs to visualize the exectution result.

 #+NAME:assignment-semantics
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   # Scalar assignment, the assignment has copy semantics
   x = 1  # value 1 has a label x
   y = x  # value 1 has another label y
   y = y -1                        # the value referred by y has changed, subtracted by 1,
   # it's a different value, no longer the same value as the one referred by x and y before.
   # x still refers to the previous value
   z = x
   w = y                           # now y refers to a new value

   # array, one dimension, assignment has no copy semantics:

   x_array = [1, 2, 3]
   y_array = x_array
   y_array[0] = -1
   z = x_array                     # The array value referred by x_array is also modified in the same way

   # use list.copy for one dimension array to implement the copy semantics:

   x_array = [1, 2, 3]             # the array [1, 2, 3] has a label x_array
   y_array = x_array.copy()        # y_array refers to a new list, one dimensional copied from x_array, one dimensional
   y_array[0] = -1                 # using the label, y_array, modify the value's element
   z = x_array                     # I expect that value referred by x_array name would not be modified,
   # as y_array now refers to a different value.
   w = y_array                     # I expect the value referred by y_array name have the value modified

   # For one dimensional list, use full extent list slicing would work as well as list.copy():
   x_array = [1, 2, 3]
   y_array = x_array[:]
   y_array[0] = -1
   z = x_array

   # array, two dimensions, assignment has no copy semantics

   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = x_array_array
   y_array_array[0][0] = -1
   z = x_array_array               # the two-dimensional array value referred by x_array has been modified
   w = y_array_array

   # Try list.copy() for two dimensions array: (it has no real copy semantics, as it's just a shallow copy)

   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = x_array_array.copy()
   y_array_array[0][0] = -1
   z = x_array_array
   w = y_array_array

   #For multi-dimensions, deepcopy from copy module must be used to work :
   from copy import deepcopy
   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = deepcopy(x_array_array)
   y_array_array[0][0] = -1
   print(x_array_array)
   print(y_array_array)

   # For 2-D list, using explicit slicing would be faster than deepcopy:
   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = [row[:] for row in x_array_array]
   y_array_array[0][0] = -1
   print(x_array_array)
   print(y_array_array)



   grid = [[0, 0],
           [1, 0]]

   a_copy = deepcopy(grid)

   for x in range(len(a_copy)):
     for y in range(len(a_copy[0])):
       a_copy[x][y] = -1

   x = grid
 #+END_SRC

 The moral of the story, in Python, assignment never makes a copy of the value referred by the name.
 To copy, the action must be explicit.

 #+RESULTS: assignment-semantics
 : None

*** The concept of variable/label scope in Python

    Only function introduces new scope besides the global scope at the module/file level (variable/label assignment)

    The other code block of if, for, etc. does not introduce new scope. The scope would be the same as the enclosing scope.
    This seems simpler and different from C++, or Scala, even Clojure!

*** List comprehension is functional, only provide values, but does not provide the modification side effect!

    It's not possible to modify element in list comprehension, as illustrated by the following example:

 #+NAME:verify-modification-by-list-comprehension
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   expand = [1, 2, 3]

   for cell in expand:
       cell = cell * 2

   x = expand

   new_expand = [-1 for cell in expand]

 #+END_SRC

 In this example, expand was not modified. The first list comprehension, only produces the values of the doubles of the elements of expand.
 But it does not change the elements of expand.

 However, it's possible to use list comprehension to construct new value as the second list comprehension shows.
 new_expand will have the same dimensions but all value would be -1.

*** Debug Python code with pdb.set_trace()

    import pdb

    pdb.set_trace() // set break point at the location, when the program reach this location, it will enter debugger, then one can do the debug there.


*** Good practice of always defining class attributes in __init__

 Here is a test to see if I could have class member defined elsewhere other than __init__
 Python does not care if one defines class members in non __init__

 But it's a bad practice, as it might introduce the following problem, when accessing
 a member, it may not have been created as it might be done in another function not yet called.

 So it's a good discipline always define all members with initial value at __init__, as it
 will be guaranteed to be called before all other methods.

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   class Foo(object):
       def __init__(self):
           #self.x = 0
           pass

       def a(self):                # may not be called before calling self.b
           self.x = 1

       def b(self):
           return self.x

   foo = Foo()
   # foo.a() # AttributeError: 'Foo' object has no attribute 'x'
   b = foo.b()
 #+END_SRC

*** Note: 0 in Python is considered as False in logic evaluation

 So
 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   light_waypoint = 273
   state = 0
   if light_waypoint and state:
       print(1)
   else:
       print(2)


 #+END_SRC
 would always print 2, as light_waypoint and 0 evaluate to False
 !!!

*** Always check if a value could be None before comparing it with an arrary (numpy)

 Python implementation may not like to have comparison between a value None and an array,
 while a function obtained from polyfit might be represented as an array internally.
 So the kosher way of coding should be:

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
 if pontential_None and (potential_None == an_numpy_array_representation)
 #+END_SRC

 #+BEGIN_EXAMPLE
 The error message could be:
 File "/usr/lib/python2.7/dist-packages/numpy/lib/polynomial.py", line 1203, in __eq__
     if self.coeffs.shape != other.coeffs.shape:
 AttributeError: 'NoneType' object has no attribute 'coeffs'
 #+END_EXAMPLE


*** Pecularity of Python
    - Unique use of else
      For in the context of try: except: else:
      It will provide the code space for code block to be executed when there is no exception happens.
      (Note, related in the context of try: except: finally:
      below the finally
      the code block will be executed if exception happens and after all exception treatment has been done.
      )

      There is another unique context to use else in loop:
      The else-clause is executed when the while-condition evaluates to false.
    -
    - Note set('12345') has the following
 assertEqual({ '1', '2', '3', '4', '5' }, set('12345'))

 - Attributes names that start with a double underscore get mangled when an instance is created.
   It must be accessed through placing prefix of its class name, for example,

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   rover = Dog()
   rover.__password()              # AttributeError
   rover._Dog__password()          # worked!
 #+END_SRC

 - (1) == 1, but (1, ) is a tuple! and () is a tuple.

 - tuple("abc") == ('a', 'b', 'c')

 - Note, tuple value is immutable, but the label to a tuple can point a different tuple value!

 - 0 is equivalent to None for Boolean value.

 - For string formating, integer is not considered to be float:

 If a format specifier is for float, if the corresponding value at the run time is of integer value,
 then it would be an error as below.
 To prevent the error message of "value

In Python integers will automatically switch
from a fixed-size int representation into a variable width long representation
once you pass the value sys.maxint, which is either 2^31 - 1 or 2^63 - 1
depending on your platform.
Notice the L that gets appended here:

>>> 9223372036854775807
9223372036854775807
>>> 9223372036854775808
9223372036854775808L
From the Python manual:

Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including binary, hex, and octal numbers) yield plain integers unless the value they denote is too large to be represented as a plain integer, in which case they yield a long integer. Integer literals with an 'L' or 'l' suffix yield long integers ('L' is preferred because 1l looks too much like eleven!).

Python tries very hard to pretend its integers are mathematical integers and are unbounded. It can, for instance, calculate a googol with ease:

>>> 10**100
100000000000000000000000000000000000000000000000000000000000000000000000000000000000

*** reload: avoid restarting kernel of Jupyter Notebook when a module is modified

    The good practice is to have a notebook cell with the reload statement:
    reload(utils)
    for example for the module utils,

    This would usually work, if the module dependencies is not too complicated.

    This is much better than to restarting the kernel, which takes much longer
    time to re-execute all the code.
https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart

* Handy for projects

To view the trajectory of the car based on the data from the rosbag
#+BEGIN_SRC shell
rosrun tools diagScreenRosbag.py
#+END_SRC

To view the trajectory of the car in simulator with bigger screen size, and appropriate font size
#+BEGIN_SRC shell
rosrun tools diagScreen.py --screensize 3 --fontsize 1
#+END_SRC


* Handy SQL Database

** Create a database

create a database with Microsoft SQL Operations Studio

Create a database DWPractice, if it doesn't exist in sys.database

#+BEGIN_EXAMPLE
USE master
GO
IF NOT EXISTS (
   SELECT name
   FROM sys.databases
   WHERE name = N'DWPractice'
)
CREATE DATABASE [DWPractice]
GO

ALTER DATABASE [DWPractice] SET QUERY_STORE=ON
GO
#+END_EXAMPLE




** Reference to table in SQL (Mircorsoft SQL server)

   Fully qualified table address:

   [database-host-server].[DB-name].[schema-name].[table-name]

   For example,
   [OtherServerName].[OtherDB].[dbo].[OtherTable]

** To access other databases

   Usually a client is connected to one database, to connect additional
   database(s) (Linked Databases), in Microsoft SQL Server, use the store procedure:

   sp_addlinkedserver: http://msdn.microsoft.com/en-us/library/ms190479.aspx

   or you can get to them in SSMS from the following location in the tree of the Object Explorer:

   Server Objects-->Linked Servers

   SSMS = Microsoft SQL Server Management Studio


** User Guides to Microsoft SQL Operations Studio (SOPS)

The following one is a good one.
https://www.red-gate.com/simple-talk/sql/sql-tools/walk-around-sql-operations-studio/

This one seems also quite comprehensive:
http://blog.sqlterritory.com/2017/12/19/sql-operations-studio-comprehensive-guide/

** The concept of "explain" in Microsoft SQL Operations Studio (SOPS)

   It's like a dry run to show how a script of SQL statements would be executed
   to see how feasible or optimal it is.

** It's possible to add constraint of foreign key after a table is created and content inserted

Here is an example,
#+BEGIN_SRC sql
ALTER TABLE [dbo].[Sales_F]
ADD CONSTRAINT [FK_Sales_F_City_Id] FOREIGN KEY (City_Id) REFERENCES [dbo].[City_D] (City_Id)
ALTER TABLE [dbo].[Sales_F]
ADD CONSTRAINT [FK_Sales_F_Prod_Id] FOREIGN KEY (Prod_Id) REFERENCES [dbo].[Prod_D] (Prod_Id)
#+END_SRC

Note, ALTER TABLE [dbo].[Sales_F] is needed for each added constraint.


** Connect to SQL server of Microsoft

Using SSMS:
https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-develop-use-ssms

Provide the host IP address, the database server username and password.




** Gotcha: LineNo in Microsoft SQL Server is a reserved word should not be used as filed name!

https://stackoverflow.com/questions/4054511/what-exactly-does-the-t-sql-lineno-reserved-word-do

The symptom would be when 'LineNo' is used as field name, the editor would show
syntax error around 'LineNo'.


** With Microsoft SQL Server, Date and DateTime accept usual literal form in strings

   https://stackoverflow.com/questions/12957635/sql-query-to-insert-datetime-in-sql-server

https://technet.microsoft.com/en-us/library/ms180878(v=sql.105).aspx#StringLiteralDateandTimeFormats

Unlike Oracle or MySQL, no procedure of transformation of to_date, etc. is
needed.

But Microsoft SQL Server does support CAST and CONVERT to do the transformation.



** Never select region of text in SQL script editor of SSMS or SOPS of Microsoft when running the script

   Or, it will only execute the seletect the text as store procedure, instead of
   the whole script in the editor.

   https://stackoverflow.com/questions/25270305/initial-error-when-querying-sql-server-2012-database


** Change to table definitions

https://www.techonthenet.com/sql_server/tables/alter_table.php

Especially, for Microsoft SQL (Transact-SQL), one should use sp_rename to rename
a column (field) name.



** To be able to access all tables in different database in a database server?

The table name must be fully qualified with database name, schema name and
table name to let the statement block work. For example,

#+NAME:using-properties
#+BEGIN_SRC sql :noweb no-export :tangle
select * from OtherDW.dbo.Supplier_D
#+END_SRC

#+RESULTS: using-properties
| Supplier_Id | Supplier_Name |
|-------------+---------------|
|           1 | Walmart       |
|           2 | Amazon        |


** to execute SQL code block org-mode (literate DBMS) with Mircorsoft SQL Server on Ubuntu

Here is an good example of literate DBMS:
http://www.howardism.org/Technical/Emacs/literate-database.html

So far to to be execut SQL block in org-mode with Microsoft SQL Server,
the header arguments must be explicitly placed at the header of an SQL block.
(Defining them as properties doesn't work! It is supposed to work per
https://www.gnu.org/software/emacs/manual/html_node/org/Header-arguments-in-Org-mode-properties.html
)

#+NAME:test
#+BEGIN_SRC sql :noweb no-export :tangle :engine mssql :cmdline "-S localhost -U SA -P 27Wangzi15"
select * from [DWPractice].[dbo].[Sales_F]
#+END_SRC

#+RESULTS: test
| City_id | Prod_id |      Month | Customer_Id | Supplier_Id | Units | Dollars |
|---------+---------+------------+-------------+-------------+-------+---------|
|       1 |     288 | 2008-01-01 |           3 |           1 |     4 |  7.3200 |
|       1 |     288 | 2008-02-01 |           1 |           1 |    16 | 42.4000 |
|       1 |     589 | 2008-01-01 |           1 |           2 |     3 |  7.9500 |
|       2 |     288 | 2008-01-01 |           2 |           2 |     4 |  7.3200 |
|       2 |     589 | 2008-01-01 |           2 |           1 |     3 |  7.9500 |

#+NAME:test-1
#+BEGIN_SRC sql :noweb no-export :tangle :engine mssql :cmdline "-S localhost -U SA -P 27Wangzi15"
select * from OtherDW.dbo.Supplier_D
#+END_SRC

#+RESULTS: test-1
| Supplier_Id | Supplier_Name |
|-------------+---------------|
|           1 | Walmart       |
|           2 | Amazon        |


*** Use global properties in org-mode
 But using global properties setting would work:
 #+PROPERTY: header-args:sql :engine mssql :cmdline -S localhost -U SA -P 27Wangzi15



** A very practical web site on SQL tips

https://blog.sqlauthority.com/2009/07/17/sql-server-two-methods-to-retrieve-list-of-primary-keys-and-foreign-keys-of-database/
* Handy Networking

** Check whether a port is opened or not in Unix/Linux/Ubuntu

good ways to find out what ports are listenting and what your firewall rules are:

    sudo netstat -tulpn

    sudo ufw status
https://askubuntu.com/questions/9368/how-can-i-see-what-ports-are-open-on-my-machine

** Find out the IP address of my computer of Ubuntu

ifconfig

looking for the interface with the significant traffic.

Or,

route

looking for the line start with 'default'.
