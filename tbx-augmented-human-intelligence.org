#+TITLE: tbx (toolbox) for productivity in information processing

* Introduction

This is my collection of know-how and utilities to make my coding as well as a shell script more convenient and productive.
Another purpose is to limit the surface of my tool chains so that I can be productive.
Ergonomically, the tool chain surface needs to be limited for human to master it comfortably and fluently.

In this document, not only scripts will be produced but also sample code segment and instructions would be shown.
This document embeds code with literate programming. The code can be generated
from this document, if needed. But most of the time, the code servers as
example, and illustration.

There will be organized into groups. One of the groups will be file utilities,
another group will be pre-processing for machine learning.

They will be mostly higher-level wrappers of the existing libraries.
This will serve the purpose of less memory overload.
Using these groups of utilities you can reduce the need to remember numerous libraries.

There may be many useful software libraries but I need to have effective entry
point
so that I can get my job done quickly reducing the load of memory and the load of searching the right tool.
It is vitally important to have personal toolboxes to be productive, as one can be sure to be familiar with the toolbox.
With these personal toolboxes, the API surface can be focused and limited to suit one's needs and habit.

In broader sense, there should research and effort on how to augment human intelligence (AHI) with computation tools.
For the purpose,
ergonomic tool surface may be an interesting research area.

* Resolution between mindmap and org-mode

I will use mindmap for knowledge acquisition at the top level, and for
thought exploration purpose, as the 2D dimensions is still better than org-mode's mainly
1D dimension.

I will use org-mode for extensive narrative of text. I may use emacs text-mode for
formatting some mindmap entries.

The drawback of mindmap is that

- it's still not possible to publish directly from mindmap.
- it's hard to search the mindmaps.
- it's much less effective to write large chunk of texts, without the auto
  completion help that's available in emacs.
- It's not possible to do version control effectively on mindmaps.

The idea combination would be to use emacs org-mode as the medium, but make it
possible to render and present the content of org-outline into mindmaps.
It might be possible, like a mindmap viewer off emacs, like one can view PDF
file in emacs.

* Unsolved problems

Here are records of unresolved problems, to save repeating effort.

** How to keep my notes easier to search over my whole computer?

I have lots of notes scatter in Freeplane files, org files, etc. I'd like to be able to search them for key words.
For examples, I'd like to know the notes about "TensorFlow" in all my files.

I might write a wrapper utility to find all the files scatter, and then search
in them.

** Not able to view *.mov file on Ubuntu with VLC and totem: alternative solution: use mplayer

For VLC, here is the error message:
as of[2017-11-21 Tue 09:59]
#+BEGIN_EXAMPLE
  Failed to open VDPAU backend libvdpau_nvidia.so: cannot open shared object file: No such file or directory
#+END_EXAMPLE

Following the suggestion from https://askubuntu.com/questions/13487/gnome-mplayer-failed-to-open-vdpau-backend-libvdpau-nvidia-so-error
did not work, as it suggested to add:

The following with sudo would not evaluate with C-c C-c
#+BEGIN_SRC shell
  sudo ln -s /usr/lib/vdpau/libvdpau_nvidia.so.1 /usr/lib/libvdpau_nvidia.so
#+END_SRC

#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence
: 1

The following is the way to execute commands
"Evaluation of this shell code block is disabled" emacs babel with sudo in babel:
#+NAME:
#+BEGIN_SRC emacs-lisp
  (let ((default-directory "/sudo::"))
    (shell-command "ln -s /usr/lib/vdpau/libvdpau_nvidia.so.1 /usr/lib/libvdpau_nvidia.so"))
#+END_SRC

But I checked the file/link has aleardy existed:

#+BEGIN_SRC shell
Pybites.  ls -lt /usr/lib/vdpau/libvdpau_nvidia.so.1
#+END_SRC

#+RESULTS:
: lrwxrwxrwx 1 root root 55 Nov  4 12:59 /usr/lib/vdpau/libvdpau_nvidia.so.1 -> /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1

I chased the symbolic link:

#+BEGIN_SRC shell
ls -lt /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1
ls -lt /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1
#+END_SRC

#+RESULTS:
| lrwxrwxrwx | 1 | root | root | 46 | Nov | 4 | 12:59 | /etc/alternatives/x86_64-linux-gnu_libvdpau_nvidia.so.1 | -> | /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1 |
| lrwxrwxrwx | 1 | root | root | 25 | Nov | 2 | 12:42 | /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.1          | -> | libvdpau_nvidia.so.384.98                      |

#+BEGIN_SRC shell
ls -lt /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.384.98
#+END_SRC

#+RESULTS:
: -rw-r--r-- 1 root root 888288 Oct 26 14:40 /usr/lib/nvidia-384/vdpau/libvdpau_nvidia.so.384.98

so at the end of the symbolic link, the target file did exist!

But vlc still complainted.

The problem with totem is simply just crash.

The alternative of using mplayer to view the same file worked. So the case is closed for now,[2017-11-21 Tue 10:23]


* Handy Machine Learning and Data Science
** Pre-processing for machine learning

*** prepare_training_samples

    Move the samples in path according to their categories into their corresponding directories named by their categories.
    This is a convention in Keras deep learning.

    The determination of the category for a sample (file) is determined by the function category_f.
    It should raise ValueError exception if there is no category can be found for the sample.
    If there is no category found for a sample (file), then do nothing against (pass).

    #+NAME:prepare_training_samples
    #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
      def prepare_training_samples(path, category_f):
          path = os.path.expanduser(path)

          for f in os.listdir(path):
              try:
                  category_gory_dir = path + category_f(f) + '/'
                  mkdir_if_not(category_dir)
                  shutil.move(path + f, category_dir)
              except ValueError as e:
                  pass
    #+END_SRC
    Use shutil.move is considered more higher level than os.rename.

**** category_f

     Categorize the training data for you to file of a training center computer category based on the computer depository make directory if needed then move that piece of data into that corrupt responding categories I can generalize the function of category for a training file (image)

     An instance of category_f to determine the category of a file,
     by the first segment of the proper file name (the segments are separated by dot '.'.

     #+NAME:category_f_by_name
     #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
       def category_f(file_name):
           file_name = os.path.basename(file_name)
           proper_name = os.path.splitext(file_name)[0]
           return proper_name[:proper_name.index('.')]
     #+END_SRC

*** Randomly select a sublist

 #+NAME:random_sublist
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
   lst = [1, 2, 3, 4, 5, 6]
   def random_split(lst, x):
       import random
       random.shuffle(lst)

       return lst[:x], lst[x:]

   train, valid = random_split(lst, 2)

 #+END_SRC

*** validation_split

 #+NAME:validation_split
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/preProcessingML.py :exports none
   def validation_split(train_dir, valid_dir=None, valid_percentage=0.01):
       """
       Splitting from training set samples for validation.
       The training samples are in train_dir.
       The validation samples should be in valid_dir.
       The valid_percentage is the percentage of the training set to be validation.

       It is assumed that train_dir have samples organized into subdirectories named by categories.
       """
       from pathlib import Path, PurePosixPath
       import os, shutil
       valid_dir = valid_dir or PurePosixPath(train_dir).parent.joinpath('valid').as_posix()
       pathlib.Path(valid_dir).mkdir(exist_ok=True)
       for d in os.listdir(train_dir):
           lst = os.listdir(train_dir+d)
           valid_len = int(len(lst)*valid_percentage)
           valid_lst, _ = random_split(lst, valid_len)
           p_valid_sub = valid_dir+d
           pathlib.Path(p_valid_sub).mkdir(exist_ok=True)
           for f in valid_lst:
               shutil.move(train_dir+d+'/'+f, p_valid_sub)
 #+END_SRC

** Confirmation of GPU working with TensorFlow

 #+NAME:if-GPU-works
 #+BEGIN_SRC python :noweb yes :tangle ~/tmp/verify_gpu_tensorflow.py :exports none
   import tensorflow as tf
   with tf.device('/gpu:0'):
       a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')
       b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')
       c = tf.matmul(a, b)

   with tf.Session(config=tf.ConfigProto(log_device_placement=True)) as sess:
       print (sess.run(c))
 #+END_SRC

 Below output from the shell console where jupyter notebook server is run shows that GPU with TensorFlow is working:

 2017-08-08 10:27:53.180144: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.1 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180170: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use SSE4.2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180176: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180181: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use AVX2 instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.180185: W tensorflow/core/platform/cpu_feature_guard.cc:45] The TensorFlow library wasn't compiled to use FMA instructions, but these are available on your machine and could speed up CPU computations.
 2017-08-08 10:27:53.528010: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:893] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero
 2017-08-08 10:27:53.528649: I tensorflow/core/common_runtime/gpu/gpu_device.cc:940] Found device 0 with properties:
 name: GeForce GTX 1070
 major: 6 minor: 1 memoryClockRate (GHz) 1.645
 pciBusID 0000:01:00.0
 Total memory: 7.92GiB
 Free memory: 7.32GiB
 2017-08-08 10:27:53.528682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:961] DMA: 0
 2017-08-08 10:27:53.528692: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   Y
 2017-08-08 10:27:53.528713: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1030] Creating TensorFlow device (/gpu:0) -> (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0)
 Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0
 2017-08-08 10:27:53.609874: I tensorflow/core/common_runtime/direct_session.cc:265] Device mapping:
 /job:localhost/replica:0/task:0/gpu:0 -> device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0

 MatMul: (MatMul): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629104: I tensorflow/core/common_runtime/simple_placer.cc:847] MatMul: (MatMul)/job:localhost/replica:0/task:0/gpu:0
 b: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629124: I tensorflow/core/common_runtime/simple_placer.cc:847] b: (Const)/job:localhost/replica:0/task:0/gpu:0
 a: (Const): /job:localhost/replica:0/task:0/gpu:0
 2017-08-08 10:27:53.629131: I tensorflow/core/common_runtime/simple_placer.cc:847] a: (Const)/job:localhost/replica:0/task:0/gpu:0


** Recommended reading for data scientist

 These are content of substance:

 http://neuralnetworksanddeeplearning.com/chap4.html

 http://blog.kaggle.com/category/winners-interviews/

 https://distill.pub/

** About GPU/Nvidia

*** What is CUDA and cuDNN?
      CUDA - API/Language to talk to the GPU.
          CUDA is NVIDIA’s language/API for programming on the graphics card. I’ve found it to be the easiest way to write really high performance programs run on the GPU.  <https://developer.nvidia.com/cudnn>
      cuDNN - library for Deep Learning using CUDA.
          cuDNN is a library for deep neural nets built using CUDA. It provides GPU accelerated functionality for common operations in deep neural nets. You could use it directly yourself, but other libraries like TensorFlow already have built abstractions backed by cuDNN.


* Handy software engineering
** File handling

 This group should complement shutil and pathlib of Python. (shutil is of higher level than os package. pathlib is an object oriented for Path concept.)

 With pathlib, mkdir_if_not can be directly implemented. This may be revisited to use pathlib.

 #+NAME:mkdir_pathlib
 #+BEGIN_SRC python :noweb yes :tangle :exports none

   Path.mkdir(mode=0o777, parents=False, exist_ok=False)

       Create a new directory at this given path. If mode is given, it is combined with the process’ umask value to determine the file mode and access flags. If the path already exists, FileExistsError is raised.

       If parents is true, any missing parents of this path are created as needed; they are created with the default permissions without taking mode into account (mimicking the POSIX mkdir -p command).

       If parents is false (the default), a
 all I needed is to change the build location and point it to '../build' directorymissing parent raises FileNotFoundError.

       If exist_ok is false (the default), FileExistsError /media/yubrshen/DATA/ai-studyis raised if the target directory already exists.

       If exist_ok is true, FileExistsError exceptions will be ignored (same behavior as the POSIX mkdir -p command), but only if the last path component is not an existing non-directory file.

       Changed in version 3.5: The exist_ok parameter was added.

 #+END_SRC

 Also pathlib provides touch function.
 #+NAME:touch_pathlib
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   from pathlib import Path

   Path('path/to/file.txt').touch()
 #+END_SRC

 I should always do expand user (~) for pathname to be sure that they are absolute path to avoid trouble down the road of further processing in all my libraries.

*** Preamble

    Import etc.

    #+NAME:preamble_file
    #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
      import os, shutil
    #+END_SRC

*** mkdir_if_not

    Make directory specified if it does not exist.
    It returns the tuple of path of the directory and the boolean wthether the directory exists (should by true).
    It handles the exception that the directory might be created after checking its existence.

  #+NAME:mkdir_if_not
  #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
   def mkdir_if_not(path):
       path = os.path.expanduser(path)
       if not os.path.exists(path):
           import errno
           try: # use try to avoid repeated creating the directory, if it's created after the above checking
               os.makedirs(path)
           except OSError as e:
               if e.errno != errno.EEXIST:
                   raise
       return path, os.path.exists(path)
 #+END_SRC

*** unzip

    unzip a file specified by file_zipped to the directory specified by target_path,
    making sure the target_path do exist.

 #+NAME:unzip
 #+BEGIN_SRC python :noweb yes :tangle ./src/python3/fileTbx.py :exports none
   def unzip(file_zipped, target_path):
       target_path = os.path.expanduser(target_path)
       mkdir_if_not(target_path)
       import zipfile
       with zipfile.ZipFile(file_zipped, 'r') as zip_ref:
           zip_ref.extractall(target_path)
 #+END_SRC

*** random_file_name

    Generate a random file name with suffix as parameter.

 #+NAME:random_file_name
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   import random, string, os

   def random_file_name(suffix, length=10):
       return ''.join(random.choice(string.lowercase) for i in range(length)) + '.' + suffix

 #+END_SRC

 #+NAME:random_file_name_test
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   file_name = random_file_name('txt')

   status = os.path.exists(file_name)

   def touch_old(fname, times=None):
       with open(fname, "a"):
           os.utime(fname, times)

   status = os.getcwd()
   import pathlib
   pathlib.Path(file_name).touch()
   status = os.path.exists(file_name)


 #+END_SRC


*** Finding files


**** Find files by modification time

Find files that are more than 10 days old:
#+BEGIN_SRC shell
find -mtime +10
#+END_SRC

Find the top level directory (-type d) for the current directory.
#+BEGIN_SRC shell
find -type d -maxdepth 1 -mtime +15
#+END_SRC
-type f
for ordinary file, non-directory

-name *.txt
for name pattern

Find the top level files/directories more 15 days old, and remove them recursively and forcefully.
#+BEGIN_SRC shell
find -maxdepth 1 -mtime +15 -exec rm -rf '{}' \;
#+END_SRC

**** Find files by extension, or type

   The following snippet works, but it took a long time. Amazingly long.
   Outside of emacs, it took much shorter time.

   #+BEGIN_SRC shell
   find /media/yubrshen/DATA/ai-study -regex ".*\.\(mm\)"
   #+END_SRC

   #+RESULTS:
   | /media/yubrshen/DATA/ai-study/ASimpleNeuralNetworkModuleForRelat.mm                                                             |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/elastic-weight-consolidation/ElasticWeightConsolidation.mm                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/machine-learning-top-level.mm                                                                     |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/Key-Concepts-for-Term-One-of-SDC-ND.mm                                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/session-leader/DevelopmentForUdacitySessionLeader.mm                                          |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/session-leader/FindingStraightLane.mm                                                         |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-Vehicle-Detection/Notes                                                          | on | Project | of                | Vehicle  | Detection  | and | Tracking.mm |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-behavior-cloning/Notes                                                           | on | project | of                | behavior | cloning.mm |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/CarND-Traffic-Sign-Classifier-Project/TrafficSignClassificationProject.mm              |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/SDC-term-1-notes.mm                                                                    |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/SystematicEvaluationOfCNNAdvancesOn.mm                                                 |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-1/vehicle-surrounding/To-brain-storms.mm                                                 |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term-2/notes-course/Key-concepts-SDC-term-2.mm                                                |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/notes/scratch.mm                                                                        |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/Capstone-Study/Clarification                                                   | of | stop    | considerations.mm |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/CarND-Capstone/clarify-stop-scenario-algorithm.mm                              |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/CarND-Path-Planning-Project/Development-of-congestion-model-in-traffic-lane.mm |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/sdc/term3/projects/ROS_pratcice/ROS-notes.mm                                                      |    |         |                   |          |            |     |             |
   | /media/yubrshen/DATA/ai-study/ShenzhenTransportProjectStudy.mm                                                                  |    |         |                   |          |            |     |             |


*** Monitor file(s) change and repeat command
    when-changed <files> -c command

    This will repeat the command once the files change.
    It's a python program, I've installed in my system.

** Shell scripts know-how

*** cd - change to previous directory

#+BEGIN_SRC shell
pwd
cd ~/tmp
pwd
cd - # expect to /home/yubrshen/programming/tbx-augmented-human-intelligence
cd - # expect to ~/tmp
#+END_SRC

#+RESULTS:
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |

*** cd ~- and cd ~+

~- as a general expression for the previous directory
~+ as the current directory

#+BEGIN_SRC shell
  echo ~+                         # equivalent to pwd: /home/yubrshen/programming/tbx-augmented-human-intelligence
  cd ~/tmp
  echo ~-                         # show the previous directory: /home/yubrshen/programming/tbx-augmented-human-intelligence
  echo ~+                         # pwd: /home/yubrshen/tmp
  cd /tmp
  echo ~+                         # pwd: /tmp
  echo ~- # previous directory: /home/yubrshen/tmp
#+END_SRC

#+RESULTS:
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |
| /home/yubrshen/tmp                                          |
| /tmp                                                        |
| /home/yubrshen/tmp                                          |

*** Difference between cd - and cd - > /dev/null
 > /dev/null suppress output

#+BEGIN_SRC shell
cd ~/tmp
cd -
#+END_SRC

#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence

#+BEGIN_SRC shell
cd - > /dev/null
#+END_SRC

#+RESULTS:

*** Meaning of && in shell commands

Continue, sequential execution

#+BEGIN_SRC shell
echo "Wish you" && echo " Happy New Year!"
#+END_SRC

#+RESULTS:
| Wish  | you |       |
| Happy | New | Year! |

*** pwd and pwd -P

#+BEGIN_SRC shell
pwd
#+END_SRC

with -P just treat symbolic as ordinary path
#+RESULTS:
: /home/yubrshen/programming/tbx-augmented-human-intelligence
#+BEGIN_SRC shell
pwd -P
#+END_SRC
with -P translate symbolic link into physical file
#+RESULTS:
: /media/yubrshen/DATA/programming/tbx-augmented-human-intelligence

*** Putting command outcome to an variable

#+BEGIN_SRC shell
  date=`date`
  echo $date
#+END_SRC

#+RESULTS:
: Sat Dec 30 15:39:30 PST 2017

The same as above to collect output of command:
#+BEGIN_SRC shell
data="$(date)"
echo $data
#+END_SRC

#+RESULTS:
: Sat Dec 30 18:04:25 PST 2017

Create a test script to show the meaning of $0
$0 is the full path of the script.

#+BEGIN_SRC shell
echo 'echo "here is the  full path of script: " "$0"  ' > ~/tmp/tmp.sh
echo 'echo "and here is the folder of the script: " "$(dirname "$0")"' >> ~/tmp/tmp.sh
chmod u+x ~/tmp/tmp.sh
~/tmp/tmp.sh
#+END_SRC

#+RESULTS:
| here | is   | the | full | path   | of | script: | /home/yubrshen/tmp/tmp.sh |                    |
| and  | here | is  | the  | folder | of | the     | script:                   | /home/yubrshen/tmp |

Putting the pieces together:

1. Extract the folder of the path.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(dirname $A_FULL_PATH)"
echo $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |
| /home/yubrshen/tmp        |

2. Use the extracted folder to change into that folder.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)")"
echo "THIS_DIR: " $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |
| THIS_DIR:                 |

1. Then capture the folder path from pwd -P
This would provide the absolute path throug pwd -P, but "$(dirname "$0")" would only provide the relative path
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P)"
echo "THIS_DIR: " $THIS_DIR
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh |                    |
| THIS_DIR:                 | /home/yubrshen/tmp |

4. Then change back to the previous folder before changing into the folder.
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
echo "THIS_DIR: " $THIS_DIR
pwd
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh                                   |                    |
| THIS_DIR:                                                   | /home/yubrshen/tmp |
| /home/yubrshen/programming/tbx-augmented-human-intelligence |                    |

5. Use the captured folder name to construct a file path
#+BEGIN_SRC shell
A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
echo $A_FULL_PATH
THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
echo "THIS_DIR: " $THIS_DIR
USER_PROFILE="$THIS_DIR/profile.tmp"
echo $USER_PROFILE
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |
| THIS_DIR:                      | /home/yubrshen/tmp |
| /home/yubrshen/tmp/profile.tmp |                    |

6. Check the existence of the file

#+BEGIN_SRC shell
  A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
  echo $A_FULL_PATH
  THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
  echo "THIS_DIR: " $THIS_DIR
  USER_PROFILE="$THIS_DIR/profile.tmp"
  echo $USER_PROFILE
  if [ ! -f "$USER_PROFILE" ];
     then
     echo "What is the full path to your Unity simulator?"
  fi
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |     |      |      |    |      |       |            |
| THIS_DIR:                      | /home/yubrshen/tmp |     |      |      |    |      |       |            |
| /home/yubrshen/tmp/profile.tmp |                    |     |      |      |    |      |       |            |
| What                           | is                 | the | full | path | to | your | Unity | simulator? |

7. Read from terminal from user input
#+BEGIN_SRC shell
  A_FULL_PATH="/home/yubrshen/tmp/tmp.sh"
  echo $A_FULL_PATH
  THIS_DIR="$(cd "$(dirname $A_FULL_PATH)" && pwd -P && cd - > /dev/null)"
  echo "THIS_DIR: " $THIS_DIR
  USER_PROFILE="$THIS_DIR/profile.tmp"
  echo $USER_PROFILE
  if [ ! -f "$USER_PROFILE" ];
     then
     echo "What is the full path to your Unity simulator?"
     read unity_path
     echo $unity_path
  fi
#+END_SRC

#+RESULTS:
| /home/yubrshen/tmp/tmp.sh      |                    |     |      |      |    |      |       |            |
| THIS_DIR:                      | /home/yubrshen/tmp |     |      |      |    |      |       |            |
| /home/yubrshen/tmp/profile.tmp |                    |     |      |      |    |      |       |            |
| What                           | is                 | the | full | path | to | your | Unity | simulator? |
|                                |                    |     |      |      |    |      |       |            |

As I don't know how to execute the shell with input, the following script needs to be executed at a terminal prompt to test.

#+BEGIN_SRC shell
  echo 'echo "Please input your name:"' > ~/tmp/prompt-input-tmp.sh
  echo 'read name' >> ~/tmp/prompt-input-tmp.sh
  echo 'echo $name' >> ~/tmp/prompt-input-tmp.sh
  chmod u+x ~/tmp/prompt-input-tmp.sh
  ls -lt ~/tmp/prompt-input-tmp.sh
  # cat ~/tmp/prompt-input-tmp.sh
  script=$(cat ~/tmp/prompt-input-tmp.sh)
  echo $script
#+END_SRC

#+RESULTS:

By executing the generated the script, here is the trace of the execution:

#+BEGIN_QUOTE
$ ~/tmp/prompt-input-tmp.sh
Please input your name:
Jonah
Jonah
#+END_QUOTE

Get one line of content from a file to a variable

#+BEGIN_SRC shell
  script=$(cat ~/tmp/prompt-input-tmp.sh)
  echo $script
#+END_SRC

#+RESULTS:
: Please input your name:

*** bash: the last argument of the previous command !$

 #+BEGIN_SRC shell
#!/usr/bash
echo "Hello"
echo !$
 #+END_SRC

 #+RESULTS:
 | Hello |
 | !$    |


** Effective with git (github)

*** To be able to access new branches in remote repository that I have cloned from

    It takes the following:

 #+BEGIN_SRC shell
 git pull
 #+END_SRC
 at a any current branch, to get the meta data of the new branches

*** To access remote branch

 #+BEGIN_SRC shell
 git checkout <path-of-a-branch>
 #+END_SRC
 for example, the path-of-a-branch may origin/tl_detector_sj

*** To set tracking branch with the remote branch

 #+BEGIN_SRC shell
 git branch --set-upstream-to=origin/tl_detector_sj merge-from-tl-detector-sj
 #+END_SRC

 tl_detector_sj is the name of the remote branch.
 merge-from-tl-detector-sj is the name of the local branch corresponding

*** Adding a local existing project to GitHub

1. Create a new repository on GitHub. ...
2. Open TerminalTerminalGit Bash.
3. Change the current working directory to your local project.
4. Initialize the local directory as a Git repository. ...
5. Add the files in your new local repository. ...
6. Commit the files that you've staged in your local repository.
7. Execute a script at the directory of the project to be added, for example, add-new-repository predict-stop-sign-slant-angle

   The script add-new-repository is written by me. It takes an argument of the
   name of the repository newly created on GitHub.

*** Access github without username and password

    The key is to define the remote origin in the fashion working with ssh.
    One can follow this: [[https://gist.github.com/developius/c81f021eb5c5916013dc][Set up GitHub push with SSH keys]]

    The key is to have the following:

    git remote set-url origin git@github.com:username/your-repository.git

    then one can do git pull and git push without being bothered by prompts of username and password.

    However, once with ssh set up, actually even the correct username/password would not work, thus
    one has to use ssh!

    For Mac machine, following the link: https://help.github.com/articles/generating-a-new-ssh-key-and-adding-it-to-the-ssh-agent/

    It's need to add the private key to the local ssh-agent:

#+NAME:
#+BEGIN_SRC shell
# Start the ssh-agent in the background.
eval "$(ssh-agent -s)"
# Agent pid 59566

# Add your SSH private key to the ssh-agent. If you created your key with a different name, or if you are adding an existing key that has a different name, replace id_rsa in the command with the name of your private key file.
ssh-add ~/.ssh/id_rsa
#+END_SRC


*** Shell script to add to a new github repository

  The following script performs the initial upload of a local repository to a newly created github repository.
  The resulted script is in "~/bin/add-new-repository"

  The script's execution permission need to be changed after tangled.

  #+BEGIN_SRC sh
     chmod 704 ~/bin/add-new-repository
  #+END_SRC

  The following is an example of the execution.
  #+BEGIN_SRC sh
     add-new-repository write-slides-with-jupyter
  #+END_SRC

  It must have one argument of the name of the repository.

  #+NAME:add-new-repository
  #+BEGIN_SRC python :noweb yes :tangle ~/bin/add-new-repository :exports none
     #!/home/yubrshen/miniconda3/bin/python
     from subprocess import call
     import sys
     #git remote set-url origin git@github.com:yubrshen/write-slides-with-jupyter.git
     #git remote add origin git@github.com:yubrshen/write-slides-with-jupyter.git
     user_host = "git@github.com:yubrshen/"
     url = user_host + sys.argv[1] + ".git"
     #action = "set-url"
     action = "add" # for initial setup origin url
     call(["git", "remote", action, "origin", url])  # this works!
     call(["git", "push", "origin", "master"])
  #+END_SRC

  Note: to have the command line arguments working, each parameter separated by space
  must be a separated element in the array.

*** Shell script to clone a repository with ssh setup
  The following script performs git clone a repository but with ssh setup for the repository.
  The resulted script is in "~/bin/git-clone-with-ssh"

  The script's execution permission need to be changed after tangled.

  #+BEGIN_SRC sh
     chmod 704 ~/bin/git-clone-with-ssh
  #+END_SRC

  The following is an example of the execution.
  #+BEGIN_SRC sh
   git-clone-with-ssh CarND-Path-Planning-Project
  #+END_SRC

  It must have one argument of the name of the repository.

  #+NAME:git-clone-with-ssh
  #+BEGIN_SRC python :noweb yes :tangle ~/bin/git-clone-with-ssh :exports none
     #!/home/yubrshen/miniconda3/bin/python
     from subprocess import call
     import sys
     import os
     # git clone git://github.com/username/your-repository
     repository = "git://github.com/yubrshen/" + sys.argv[1]
     call(["git", "clone", repository])
     os.chdir(sys.argv[1])
     user_host = "git@github.com:yubrshen/"
     url = user_host + sys.argv[1] + ".git"
     # git remote set-url origin git@github.com:username/your-repository.git
     call(["git", "remote", "set-url", "origin", url])
  #+END_SRC

*** Typical merge to remote branch

 Step 1: From your project repository, bring in the changes and test.

 git fetch origin
 git checkout -b hector-dev origin/hector-dev
 git merge aaron-dev

 Step 2: Merge the changes and update on GitHub.

 git checkout aaron-dev
 git merge --no-ff hector-dev
 git push origin aaron-dev

*** Merge with upstream

 The upstream can be the repository from which my repository is forked from.

 Let's define it and name it (udacity):

 #+BEGIN_SRC shell
 git remote add udacity https://github.com/user/repo.git
 #+END_SRC

 To merge modifications from udacity:

 #+BEGIN_SRC shell
 git fetch udacity
 git merge udacity/merge
 #+END_SRC

** Effective writing slides

 As of Aug., 2017, my choice of slide writing is jupyter notebook with reveal.js,
 for details, here is the tutorial on how to get started quickly.

 https://github.com/yubrshen/write-slides-with-jupyter

** Effective with Emacs

*** Set to variable that is yet to be loaded (defined)

#+NAME:
#+BEGIN_SRC emacs-lisp
(with-eval-after-load 'anaconda-mode
    (add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/sandbox")
    (add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/")
    )
#+END_SRC

python-shell-extra-pythonpaths is defined in anaconda-mode, just doing
(add-to-list 'python-shell-extra-pythonpaths "/media/yubrshen/DATA/programming/python/sandbox")
would resulting "Symbol’s value as variable is void: python-shell-extra-pythonpaths" as anaconda-mode has not been loaded.

But use the above expression, it will execute the operation after anaconda-mode is loaded.

*** Disable undersore-to-subscript in org-mode export
    Have the option in the org-mode file:
    #+OPTIONS: ^:nil

    ref: https://stackoverflow.com/questions/698562/disabling-underscore-to-subscript-in-emacs-org-mode-export
*** Understanding of org-mode's option syntax

    #+OPTIONS: ^:nil

    "#+OPTIONS:" indicate the option section
    "^:" for the option property name for subscript/supperscript
    "nil" the value to nil

*** Proper use of company mode's auto-completions
    When typing text, company mode would provide suggestions, use "TAB" key to cycle through the options.

    This is the most effective way. My former way of use "Alt-n" is too cumbersome.

*** Using CDLaTeX to enter math in org-mode

    1. In org-mode, many latex environment delimiters are recognized, and treated the text following the delimiters as latex-environment. The delimiters include
       1. Environments of any kind. The only requirement is that the \begin statement appears on a new line, at the beginning of the line or after whitespaces only.
       2. Text within the usual LaTeX math delimiters.
          To avoid conflicts with currency specifications,
          single ‘$’ characters are only recognized as math delimiters if the enclosed text contains at most two line breaks,
          is directly attached to the ‘$’ characters with no whitespace in between, and
          if the closing ‘$’ is followed by whitespace or punctuation
          (parentheses and quotes are considered to be punctuation in this context).
          For the other delimiters, there is no such restriction, so when in doubt, use ‘\(...\)’ as inline math delimiters.
    http://orgmode.org/manual/LaTeX-fragments.html#LaTeX-fragments

    2. In the latex-environment, cdlatex minor mode can be used, by: (add-hook 'org-mode-hook 'turn-on-org-cdlatex)
       1. Environment templates can be inserted with C-c {.

       2. The <TAB> key will do template expansion if the cursor is inside a LaTeX fragment1.
       For example, <TAB> will expand fr to \frac{}{} and position the cursor correctly inside the first brace.
       Another <TAB> will get you into the second brace.
       Even outside fragments, <TAB> will expand environment abbreviations at the beginning of a line.
       For example, if you write ‘equ’ at the beginning of a line and press <TAB>,
       this abbreviation will be expanded to an equation environment.
       To get a list of all abbreviations, type M-x cdlatex-command-help RET.

       1. Pressing _ and ^ inside a LaTeX fragment will insert these characters together with a pair of braces.
       If you use <TAB> to move out of the braces, and if the braces surround only a single character or macro,
       they are removed again (depending on the variable cdlatex-simplify-sub-super-scripts).

       1. Pressing the grave accent ` followed by a character inserts math macros,
       also outside LaTeX fragments. If you wait more than 1.5 seconds after the grave accent, a help window will pop up.

       1. Pressing the apostrophe ' followed by another character modifies the symbol before point with an accent or a font.
       If you wait more than 1.5 seconds after the apostrophe, a help window will pop up.
       Character modification will work only inside LaTeX fragments; outside the quote is normal.
       http://orgmode.org/manual/CDLaTeX-mode.html#CDLaTeX-mode

*** Effective navigation
    http://ergoemacs.org/emacs/emacs_navigate_lisp_code.html
**** Jump to the enclosing form or function in emacs-lisp code
     - Use backward-up-list Ctrl-Alt + u Move to parent (move to the (beginning of) outer paren pair)
**** Move to the first child
     - down-list

**** Move to next sibling
     - forward-sexp
**** Move to previous sibling
     - backward-sexp

*** Define an emacs lisp function and bind it to a key in a major mode (work-flow)
    1. Define the function: the crucial factor is to call (interactive) at the beginning of the function body.
       For example,
       #+NAME:
       #+BEGIN_SRC emacs-lisp
         (defun my-try-cdlatex-tab ()
           "Call org-try-cdlatex-tab interactively"
           (interactive)
           (org-try-cdlatex-tab))
       #+END_SRC

    2. Bind the function to a key binding in the designated major mode, manually
       To bind a key just in the current major mode, type M-x local-set-key <RET> key cmd <RET>.
       To bind a key to globally, type M-x global-set-key <RET> key cmd <RET>

    3. Recover the key binding code and put them into code file
       To make the process of binding keys interactively easier, use the following “trick”: First bind the key interactively, then
       immediately type C-x <ESC> <ESC> C-a C-k C-g. Now, the command needed to bind the key is in the kill ring, and can be yanked into your file

    4. Embed the code of local-set-key into the designated major mode hook, e.g.

      #+NAME:
      #+BEGIN_SRC emacs-lisp
        (add-hook 'org-mode-hook
                  (lambda ()
                    (local-set-key [C-S-iso-lefttab] (quote my-try-cdlatex-tab))))
      #+END_SRC
      Ref: https://www.gnu.org/software/emacs/manual/html_node/efaq/Binding-keys-to-commands.html

*** Insert figure into org file

    Use the following code to insert a figure.

 #+BEGIN_EXAMPLE
 #+CAPTION: This is the caption for the next figure link (or table)
 #+NAME:   fig:SED-HR4049
 [[./img/a.jpg]]
 #+END_EXAMPLE

 Note the figure might be captured through screenshot!


*** Do screenshot and insert the captured

    1. Show the desired image to be captured
    2. In the point of the butter to insert the screenshot, excute M-x org-download-screenshot
    3. Use the appearing mouse cross-hair pointer to select the screen area to
       be captured.

       Here is an example:


#+DOWNLOADED: /tmp/screenshot.png @ 2018-02-20 11:46:40
[[file:Handy software engineering/screenshot_2018-02-20_11-46-40.png]]


*** Permanently, and globally change the margin of org export to PDF

    (setq org-latex-packages-alist '(("margin=2cm" "geometry" nil)))
    or
    #+LATEX_HEADER: \usepackage[margin=0.5in]{geometry}

*** Write special character/symbol in org-mode
    Use command org-entities-help to find the org entity for the symbol, and
    use {} to seperate the symbol from the rest of the normal character without space in between.

    For example, =p\egrave{}re= for p\egrave{}re

*** Insists on creating new file with helm

    With helm, when accessing new file, if helm does not find any file with name containing the type substrings, then it will create one, no problem.

    But when helm found existing file's name contains the typed as substrings, by default, it will open that the matched file. But one can insist on
    creating the new file by selecting the selected file name by typing C-P, the one above the matched existing file name.

*** Retrieve last command executed

 last-command and this-command

 Normally, whenever a function is executed, Emacs
 sets the value of this-command to the function being executed.
 At the same time, Emacs sets the value of last-command to the previous value of this-command.

*** Debug in emacs
    Use realgud (M-x realgud:pdb, etc. for different language's debugger)
    With spacemacs, the keybindings of function keys are working
    f9 set break point
    mouse click on the beginning of the line where there is a breakpoint: clear the breakpoint
    f10 next
    f11, SPC, Step

    f5: continue
    S-F5: quit

    Some keybindings may not work for spacemacs

    One can also use the associated command buffer to control the debugger. Overall, it's better than using gdb, and gdbtui in Ubuntu.

    https://github.com/realgud/realgud

    As of 2017/9/6, realgud should replace my use of gdbtui on Ubuntu.



*** Mark and point

    When not in transient-mark-mode, with C-x C-x, it's possible to jump between mark and point. It's quite handy
    for situation when one pastes large chunks of text, and then would like to go back to the point at the beginning
    of the pasting. Here are the procedure:
    1. Pre-condition, transient-mark-mode disabled
    2. Set mark at the point for pasting, before the pasting action
    3. Perform the paste operation
    4. Switch between point and mark by command C-x C-x

**** How to disable transient-mark-mode

     A few options:
     - M-x transient-mark-mode to toggle the transient-mark-mode
     - or execute (transient-mark-mode 0) in configuration

**** Temporarily enable transient-mark-mode

     By command C-u C-x C-x (in spacemacs, SPACE u C-x C-x, can temporarily enable the transient-mark-mode

*** Read and make notes with PDF: interleave

    1. Create a new org file
    2. In it, put the line
 #+INTERLEAVE_PDF: <path-to-the-pdf-file>

 then start to read PDF with command M-x interleave

*** Execute shell command and place output to replace the content of the region, in spacemacs

    1. Select the region to be processed and replaced
    2. SPACE u M-! <cmd>

    SPACE u is for universal argument to replace the selected region.

*** Way to let Python live code work with particular environment:
    start the environment in a shell, and start emacs from the shell


*** Indent-region: format a region to have proper indent
    Select the region needing to reformat, then indent-region
    C-M \

*** recursive grep in a directory

    M-x rgrep

    Alternatively, (not really explored, not needed beyond rgrep).

 Use helm-projectile-grep/ack/ag: You can search for everything starting from project root. Later if you want to save the search results, press F3 or press TAB to switch to action menu and select the 3rd action. To navigate hgrep buffer:
 C-<down>: go to next match and open the match.
 C-<up>: go to previous match and open the match.
 M-<down>: go to next match without opening the match.
 M-<up>: go to next match without opening the match.
 C-o: open current match in other window.
 RET: open current match in current window.
 Use helm-projectile-find-dir (note the helm prefix; you must use proper Helm commands from helm-projectile package in general): narrow to a desired directory and press C-u C-s to recursively search in that directory. If you don't press C-u, it just searches in that directory without going deeper.

*** Unbind undo-key u

  #+NAME:unbind-undo-key-u
  #+BEGIN_SRC emacs-lisp
  (unbind-key (kbd "u") evil-normal-state-map)
  #+END_SRC

  #+RESULTS: unbind-undo-key-u

  It works that the key is no longer bound for undo

  Now the new undo key is C-_

*** make the CAPSLOCKS key as ctrl-key in Ubuntu (X-system)

    In order to prevent repetitive injury syndrom (RSI) of hands with keyboard,
    especially emacs-pinky finger injury.

 setxkbmap -layout us -option ctrl:nocaps
 https://askubuntu.com/questions/33774/how-do-i-remap-the-caps-lock-and-ctrl-keys

 Here is some command that it might be useful. (It's pasetd at the wrong place.
 I don't know if it's still useful.)

setxkbmap -device 15 us

*** Don't run long running application from emacs babel code block, it might block emacs itself.

 - such as running a video player, etc.

*** Stop evaluation of code blocks at the export

 Put it at the top of the org file,
 #+BIND: org-export-use-babel nil
 apply it by C-c C-c
 it works!

 The following does not work for me with emacs 25:

 Place the following at the top of the org file, as per file variable:
 # -*- org-export-babel-evaluate: nil -*-

*** Solve the problem of not able to execute code block in org-mode

    Sometimes, after upgrading emacs packages (probably some org-contrib packages, it would no longer
possible to execute code block with C-c C-c it would have the error of: "evaluation of code-blocks is disabled"

The current solution is to execute M-x spacemacs/recompile-elpa after an upgrade, it took a long time, but it
indeed solved the problem.

IT IS A GOOD PRACTICE TO RECOMPILE THE EMACS FILES by M-x spacemacs/recompile-elpa


*** Example of typesetting multiline equation with big brackets
Actually, a better example, would be:
\begin{eqnarray}
\label{eq:1}
 &  & \\
\end{eqnarray

\begin{equation*}\label{eq:lda}
\begin{aligned}
p(W_{d,n}, Z_{d,n}, for \ n \in \{1, \dots, N \},
\theta_d, for \ d \in \{1, \dots, D \},
\beta_k, for \ k \in \{1, \dots, K \}, \alpha, \eta) = \\
\left( \prod_{d=1}^D p(\theta_d | \alpha)
\left( \prod_{n=1}^N p(Z_{d,n} | \theta_d) p(W_{d,n} | Z_{d,n}, \beta_1, \dots, \beta_K) \right)
 \right)
\bigg(\prod_{k=1}^K p(\beta_k | \eta)\bigg)
\end{aligned}
\end{equation*}

*** To prevent linked files from being embedded of org-mode file when exported to PDF

    Use C-u C-c C-l (or Space u C-c C-l in spacemacs) with non-empty
    description.


*** To have org-capture to place the todo's into a specific files, one has to set the proper value of org-default-notes-file,
    otherwise, the system might place new notes.org in the current directory
    where the capture was happening. I explicitly set the following:
    #+BEGIN_SRC emacs-lisp
(setq org-directory "~/zoom-out")
(setq org-default-notes-file (os-path (concat org-directory "/" "notes.org")))
    #+END_SRC
    It works.

*** To have todo items showing up in the org agenda view, the value of org-agenda must be properly set.
    The org file that contains those todo items must be in the list as the value
    to org-agenda.

    Currently, the following works:
    #+BEGIN_SRC emacs-lisp
    (setq org-agenda-files (list org-default-notes-file
                             (os-path "~/Dropbox/schedule.org")))
    #+END_SRC


*** Proper value of :noweb in org-babel

    I ran into situation when use the value of tangle for :noweb when the code
    block is nested in the third level, the code block was not tangled in the
    source code. But using yes as value, then the problem is gone.

    It seems that this is a bug. That I should report.

    So the moral of the story is that I should use no-export instead of
    tangle to achieve my desired effect: to tangle and evaluate, but do not
    export.

    Here is the relevant document:
    https://orgmode.org/manual/noweb.html
    no Default. No expansion of Noweb syntax references in the body of the code when evaluating, tangling, or exporting.
    yes Expansion of Noweb syntax references in the body of the ‘src’ code block when evaluating, tangling, or exporting.
    tangle Expansion of Noweb syntax references in the body of the ‘src’ code block when tangling. No expansion when evaluating or exporting.
    no-export Expansion of Noweb syntax references in the body of the ‘src’ code block when evaluating or tangling. No expansion when exporting.
    strip-export Expansion of Noweb syntax references in the body of the ‘src’ code block when expanding prior to evaluating or tangling. Removes Noweb syntax references when exporting.
    eval Expansion of Noweb syntax references in the body of the ‘src’ code block only before evaluating.


*** How to add additional packages with modern_emacs setup with spacemacs

    There are two ways to do it:
    1. Add in the file .spacemacs.d/init.el in the list of packages for
       spacemacs-additional-packages. This only works for package that does not
       require any configuration.
    2. For package requiring configuration, it can be added in
       .spacemacs.d/layers/config/packages.el put the new package in the list
       for the value of config-packages, and then provide the function to
       configure the new package in terms of
       #+BEGIN_SRC emacs-lisp
(defun config/init-<package-name>-config ()
  (use-package <package-name>
    :after <dependency>
    :init (progrn
           )
    :config (progn
              )))
       #+END_SRC



*** Caution: when assigning string value to variable in emacs lisp, quotation "" must be used

    Otherwise, the error of "eval-buffer: Symbol's value as variable is void"

*** Address the error message of "Evaluation of code disabled" when C-C-c executing code in org-mode

    With spacemacs, after upgrading packages, this may happen. The solution is
    to execute M-x spacemacs/recompile-elpa

    Only compile ob-core.el didn't help.

    For details, see here:
    https://github.com/syl20bnr/spacemacs/issues/7641


*** Search string in a whole directory: <space>/

    This will show all the line with the text searched.

*** Position the current line, zt, zz, zb
    zt position it to the top
    zz to the center
    zb to the bottom

    There is used to be bound to CTRL-l in emacs. But it's now bound for jumping
    to positions.

    zz is equivalent to CTRL-l, z. also move to the first non-blank character



** Effective with Linux

*** How to figure out which program caused a core dump
#+NAME:gdb_core
#+BEGIN_SRC shell
gdb -c core
#+END_SRC

*** To make pandoc to pdf work, needs to install pdflatex

    The best option is to install texlive from the source

https://www.tug.org/texlive/quickinstall.html

*** Command to produce PDF from pandoc-mode for md: C-c / p
    Select output format: latex

*** To fix the problem of fonts not loadable (missing) with pdflatex/pandoc

! Font T1/cmr/m/n/10=ecrm1000 at 10.0pt not loadable: Metric (TFM) file not fou
nd.
<to be read again>
                   relax
l.105 \fontencoding\encodingdefault\selectfont

pandoc: Error producing PDF

when producing pdf from markdown (md) file, such as
pandoc manager-or-technical-program-manager/extended-cv-yushen.md -o yushen-manager.pdf

The solution in Ubuntu 18.04:
sudo apt-get install texlive-fonts-recommended

*** To fix the error of LaTeX Error: File `fancyvrb.sty' not found.

pandoc manager-or-technical-program-manager/extended-cv-yushen.md -o yushen-manager.pdf
! LaTeX Error: File `fancyvrb.sty' not found.

Type X to quit or <RETURN> to proceed,
or enter new name. (Default extension: sty)

Enter file name:
! Emergency stop.
<read *>

Solution on Ubuntu:
sudo apt-get install texlive-full

or install TexLive from the source:
https://www.tug.org/texlive/quickinstall.html



* Meta: when having error message in running program,

first copy the error message and use Google to search for related solutions or
information.

* Handy languages
** Effective C++
*** object assignment need to have default constructor to work

   For object assignment to work, the class for the object must have default constructor, taking no arugment.

*** C++ compiler can provide the copy constructor and assignment operator for call with pointer as member

   Also note, for class without pointer as member, then the copy constructor, and assignment operator can be provided by
   the compiler, no need to code manually, unless there is special requirements in the implementation.

   While with class with pointer as member, then the copy constructor and assignment operator must be manually defined,
   as it matters how "deep" the copy and assignment should be performed along the pointer.

*** #include <algorithm> needed for operator of vector of string
    In the following code,
 vector.erase(std::remove(a_vector.begin(), a_vector.end(), value), a_vector.end());

 it needs to use the special string value comparison defined in algorithm to work.
 without including algorithm, it will use the default, causing the following error:

 #+BEGIN_QUOTE
 error: cannot convert ‘std::vector<std::__cxx11::basic_string<char> >::iterator {aka __gnu_cxx::__normal_iterator<std::__cxx11::basic_string<char>*, std::vector<std::__cxx11::basic_string<char> > >}’
 to ‘const char*’ for argument ‘1’ to ‘int remove(const char*)’
    a_vector.erase(std::remove(a_vector.begin(), a_vector.end(), value), a_vector.end());

 #+END_QUOTE

 without #include <algorithm>, it will also cause the following error:

 #+BEGIN_QUOTE
 In instantiation of
 ‘typename T::iterator min_map_element(T&) [with T = std::map<std::__cxx11::basic_string<char>, float>; typename T::iterator = std::_Rb_tree_iterator<std::pair<const std::__cxx11::basic_string<char>, float> >]’:
 required from here
 error: ‘min_element’ was not declared in this scope
    return min_element(m.begin(), m.end(),

 #+END_QUOTE

*** The lifetime of auto declaration variables (objects) is within the scope where it's declared
    - auto declaration: such as int i;
    - a pair of bracket define a scope
    - a variable declared as auto variable would not have guarantee to exist outside of its declaring scope!

    [[ihttps://stackoverflow.com/questions/11137516/scope-vs-lifetime-of-variabled:][Scope vs. Lifetime of Variable]]

    Also note that Python's scope is much simpler and more generous: only function and global are scopes,
    the other code block is not scope, thus has no impact to the lifetime of Python object

*** The lifetime of returned value
    The return value from a function is temporary only guarantee to exist during the statement of calling the function.
    Therefore the returned value should be assigned to an variable in order to extend or preserve the lifetime of the returned value.

*** Enable core dump generation in Ubuntu

    On terminal to execute the following:
 #+BEGIN_SRC sh
 ulimit -c unlimited
  #+END_SRC

 to have it permanent, put the command in ~/.profile

*** Investigation of core dump file

    gdb <executable> ./core

*** To manipulate a vector as value keyed in a std::map

    The address of the vector (pointer) instead of vector value must be used. Otherwise, it would not be the same vector, but a new instance
    of empty vector.

    Anything on the left hand-side or target of manipulation, must use pointer to the address, cannot be the value.

    Note, to express a map from string to vector pointer should be as following:
    map<string, vector<double>* > // not map<string, *vector<double> >

*** Note: jupyter when running, may cause Ubuntu 16.04 not suspend properly, and it will not resume. The system has to be turned off and restarted: the solution is to kill the jupyter process

    Before suspending system.

*** Effective C++/C debug

    As of 2017/9/6, see realgud entry: [[Debug in emacs]], as it's more user friendly than gdbtui.

    Use gdbtui (GDB with GUI):
    gdbtui <path-to-executable>

    To enable cmake to setup for debug, use cmake-gui, select build type as Debug, then make on the command line.

    Major command in GDB:
    break <line number>
    run to run the loaded program
    continue to resume from breakpoint

    display <variable-name> to auto show the value of the variable
    print <variable-name> to show the value of the variable once; print *<pointer> (to show the data pointed by the pointer)

    undisplay to remove all previously displayed variables.

**** Passing arguments and rediction from standard input still works inside gdbtui

  Pass the arguments to the run command from within gdb.

  $ gdb ./a.out
  (gdb) r arg1 arg2 < t
  Starting program: /dir/a.out < t

**** Typical workflow with GDB

     1. Make
     2. gdbtui <executable>
     3. break <all interested line numbers>
     4. r arg1 arg2 < <input_in_file>
     5. examine at a breakpoint
     6. continue, repeat step 5 (the previous)

**** Running C++ program interactive with emacs/ubuntu
     There are a few options:
     1. Use cpp.sh (a web site, paste code to the code window and run). Note: when there is some crash, it may not report the error, such as segmentation fault, etc.
     2. Use my own sandbox mechanism of tangle to ~/programming/cplusplus/sandbox/src/sandbox.cpp and run in command shell (Note, the command to tangle in spacemacs is <SPACE> u C-v C-t t, not to confusing with u without <SPACE> which is undo!
     3. Use emacs org-babel executing code block, see https://emacs.stackexchange.com/questions/15065/org-mode-babel-interactive-code-block-evaluation
     4. Use Jupyter C++ kernel, see http://shuvomoy.github.io/blog/programming/2016/08/04/Cpp-kernel-for-Jupyter.html for leads

**** There is a way to construct vector literals in C++
     For example,
     vector<int> a_vector = {1, 2, 3} // This requires C++11
      There might be way to use << operation, such as
      vector<string> a_vector;
      a_vector << "Hello" << "World"; // not verified.

      Another to do it is via array initialization

  static const int arr[] = {16,2,77,29};
  vector<int> vec (arr, arr + sizeof(arr) / sizeof(arr[0]) );


**** It's complicated to find length of a C++ array, use vector instead

     int a[7];
     std::cout << "Length of array = " << (sizeof(a)/sizeof(*a)) << std::endl;

**** Use for (auto x:sequence) { <access code>}
     To traverse the sequence, to avoid confusion and mistakes with iteration variable.

**** Use C++11 for new and improved expressiveness

**** With spacemacs, I found M-x gdb works for C++ debugging

     - To set breakpoint C-x C-a C-b in a source code buffer
     - To clear a breakpoint at the place of the breakpoint, C-x C-a C-d
     - Restore multiple window layout:
  If you ever change the window layout, you can restore the many-windows layout
by typing M-x gdb-restore-windows.
To toggle between the many windows layout and a simple layout with just the GUD
interaction buffer and a source file, type M-x gdb-many-windows.
  GDB User Interface Layout - GNU Emacs Manual - GNU.org
  https://www.gnu.org/software/emacs/manual/.../emacs/GDB-User-Interface-Layout.html

  - running again will automatically reload the updated binary.

**** Build debug enabled executable from C++ source
   at the root of the project:

   cmake -DCMAKE_BUILD_TYPE=Debug build


** Effective Python

*** Use python-live-mode in emacs to visualize the execution

    In the python-live-mode, all value assigned to a variable/label would be shown it's value at the moment of label reference.
    It makes it quite clean of the program execution in terms of value changes.

    python-live-mode can be started by keys 'l in python-mode in spacemacs.

*** Avoid the trap of Python variable assignment

 deepcopy needed to copy multi-dimension list,
 Python's variable is just a label to data value.
 For container type such as list, the assignment only adds one more label for the variable on the right side of assignment to the data value referred by the variable on the left side of the assignment!
 Thus modifying using the either label would cause the same data value (container) to be modified!

 The solution is use copy for one-dimensional list, or full list slicing [:]

 For multiple dimension list, one has to use deepcopy to make actual data duplication.

 It helps to refresh to the understanding of label semantics of Python variable:  http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html#python-has-names

 Here is examples to illustrate the problems and solutions:

 In the examples, I assume using python live-mode in emacs to visualize the exectution result.

 #+NAME:assignment-semantics
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   # Scalar assignment, the assignment has copy semantics
   x = 1  # value 1 has a label x
   y = x  # value 1 has another label y
   y = y -1                        # the value referred by y has changed, subtracted by 1,
   # it's a different value, no longer the same value as the one referred by x and y before.
   # x still refers to the previous value
   z = x
   w = y                           # now y refers to a new value

   # array, one dimension, assignment has no copy semantics:

   x_array = [1, 2, 3]
   y_array = x_array
   y_array[0] = -1
   z = x_array                     # The array value referred by x_array is also modified in the same way

   # use list.copy for one dimension array to implement the copy semantics:

   x_array = [1, 2, 3]             # the array [1, 2, 3] has a label x_array
   y_array = x_array.copy()        # y_array refers to a new list, one dimensional copied from x_array, one dimensional
   y_array[0] = -1                 # using the label, y_array, modify the value's element
   z = x_array                     # I expect that value referred by x_array name would not be modified,
   # as y_array now refers to a different value.
   w = y_array                     # I expect the value referred by y_array name have the value modified

   # For one dimensional list, use full extent list slicing would work as well as list.copy():
   x_array = [1, 2, 3]
   y_array = x_array[:]
   y_array[0] = -1
   z = x_array

   # array, two dimensions, assignment has no copy semantics

   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = x_array_array
   y_array_array[0][0] = -1
   z = x_array_array               # the two-dimensional array value referred by x_array has been modified
   w = y_array_array

   # Try list.copy() for two dimensions array: (it has no real copy semantics, as it's just a shallow copy)

   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = x_array_array.copy()
   y_array_array[0][0] = -1
   z = x_array_array
   w = y_array_array

   #For multi-dimensions, deepcopy from copy module must be used to work :
   from copy import deepcopy
   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = deepcopy(x_array_array)
   y_array_array[0][0] = -1
   print(x_array_array)
   print(y_array_array)

   # For 2-D list, using explicit slicing would be faster than deepcopy:
   x_array_array = [[1, 2, 3], [3, 2, 1]]
   y_array_array = [row[:] for row in x_array_array]
   y_array_array[0][0] = -1
   print(x_array_array)
   print(y_array_array)



   grid = [[0, 0],
           [1, 0]]

   a_copy = deepcopy(grid)

   for x in range(len(a_copy)):
     for y in range(len(a_copy[0])):
       a_copy[x][y] = -1

   x = grid
 #+END_SRC

 The moral of the story, in Python, assignment never makes a copy of the value referred by the name.
 To copy, the action must be explicit.

 #+RESULTS: assignment-semantics
 : None

*** The concept of variable/label scope in Python

    Only function introduces new scope besides the global scope at the module/file level (variable/label assignment)

    The other code block of if, for, etc. does not introduce new scope. The scope would be the same as the enclosing scope.
    This seems simpler and different from C++, or Scala, even Clojure!

*** List comprehension is functional, only provide values, but does not provide the modification side effect!

    It's not possible to modify element in list comprehension, as illustrated by the following example:

 #+NAME:verify-modification-by-list-comprehension
 #+BEGIN_SRC python :noweb yes :tangle :exports none
   expand = [1, 2, 3]

   for cell in expand:
       cell = cell * 2

   x = expand

   new_expand = [-1 for cell in expand]

 #+END_SRC

 In this example, expand was not modified. The first list comprehension, only produces the values of the doubles of the elements of expand.
 But it does not change the elements of expand.

 However, it's possible to use list comprehension to construct new value as the second list comprehension shows.
 new_expand will have the same dimensions but all value would be -1.

*** Debug Python code with pdb.set_trace()

    import pdb

    pdb.set_trace() // set break point at the location, when the program reach this location, it will enter debugger, then one can do the debug there.


*** Good practice of always defining class attributes in __init__

 Here is a test to see if I could have class member defined elsewhere other than __init__
 Python does not care if one defines class members in non __init__

 But it's a bad practice, as it might introduce the following problem, when accessing
 a member, it may not have been created as it might be done in another function not yet called.

 So it's a good discipline always define all members with initial value at __init__, as it
 will be guaranteed to be called before all other methods.

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   class Foo(object):
       def __init__(self):
           #self.x = 0
           pass

       def a(self):                # may not be called before calling self.b
           self.x = 1

       def b(self):
           return self.x

   foo = Foo()
   # foo.a() # AttributeError: 'Foo' object has no attribute 'x'
   b = foo.b()
 #+END_SRC

*** Note: 0 in Python is considered as False in logic evaluation

 So
 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   light_waypoint = 273
   state = 0
   if light_waypoint and state:
       print(1)
   else:
       print(2)


 #+END_SRC
 would always print 2, as light_waypoint and 0 evaluate to False
 !!!

*** Always check if a value could be None before comparing it with an arrary (numpy)

 Python implementation may not like to have comparison between a value None and an array,
 while a function obtained from polyfit might be represented as an array internally.
 So the kosher way of coding should be:

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
 if pontential_None and (potential_None == an_numpy_array_representation)
 #+END_SRC

 #+BEGIN_EXAMPLE
 The error message could be:
 File "/usr/lib/python2.7/dist-packages/numpy/lib/polynomial.py", line 1203, in __eq__
     if self.coeffs.shape != other.coeffs.shape:
 AttributeError: 'NoneType' object has no attribute 'coeffs'
 #+END_EXAMPLE


*** Pecularity of Python
    - Unique use of else
      For in the context of try: except: else:
      It will provide the code space for code block to be executed when there is no exception happens.
      (Note, related in the context of try: except: finally:
      below the finally
      the code block will be executed if exception happens and after all exception treatment has been done.
      )

      There is another unique context to use else in loop:
      The else-clause is executed when the while-condition evaluates to false.
    -
    - Note set('12345') has the following
 assertEqual({ '1', '2', '3', '4', '5' }, set('12345'))

 - Attributes names that start with a double underscore get mangled when an instance is created.
   It must be accessed through placing prefix of its class name, for example,

 #+NAME:
 #+BEGIN_SRC python :noweb tangle :tangle
   rover = Dog()
   rover.__password()              # AttributeError
   rover._Dog__password()          # worked!
 #+END_SRC

 - (1) == 1, but (1, ) is a tuple! and () is a tuple.

 - tuple("abc") == ('a', 'b', 'c')

 - Note, tuple value is immutable, but the label to a tuple can point a different tuple value!

 - 0 is equivalent to None for Boolean value.

 - For string formating, integer is not considered to be float:

 If a format specifier is for float, if the corresponding value at the run time is of integer value,
 then it would be an error as below.
 To prevent the error message of "value

In Python integers will automatically switch
from a fixed-size int representation into a variable width long representation
once you pass the value sys.maxint, which is either 2^31 - 1 or 2^63 - 1
depending on your platform.
Notice the L that gets appended here:

>>> 9223372036854775807
9223372036854775807
>>> 9223372036854775808
9223372036854775808L
From the Python manual:

Numbers are created by numeric literals or as the result of built-in functions and operators. Unadorned integer literals (including binary, hex, and octal numbers) yield plain integers unless the value they denote is too large to be represented as a plain integer, in which case they yield a long integer. Integer literals with an 'L' or 'l' suffix yield long integers ('L' is preferred because 1l looks too much like eleven!).

Python tries very hard to pretend its integers are mathematical integers and are unbounded. It can, for instance, calculate a googol with ease:

>>> 10**100
100000000000000000000000000000000000000000000000000000000000000000000000000000000000

*** reload: avoid restarting kernel of Jupyter Notebook when a module is modified

    The good practice is to have a notebook cell with the reload statement:
    reload(utils) (for Python 2), import importlib; importlib.reload(utils) (for python 3)
    for example for the module utils,

    This would usually work, if the module dependencies is not too complicated.

    This is much better than to restarting the kernel, which takes much longer
    time to re-execute all the code.
https://support.enthought.com/hc/en-us/articles/204469240-Jupyter-IPython-After-editing-a-module-changes-are-not-effective-without-kernel-restart


*** Change Python's character coding system to support unicode processing:

The python's coding system needs to be changed to support the manipulation of unicode charaters contained in the report.
The following setup will enable the processing unicode characters. It's found to be working with Python 2.7

#+NAME:setting-for-unicode
#+BEGIN_SRC python :noweb no-export :tangle
import sys
reload(sys) # This is necessary, otherwise, the following setdefaultencoding would not be available
sys.setdefaultencoding('utf-8')
#+END_SRC

*** Capture the installed libraries in an environment

#+NAME:pip_freeze
#+BEGIN_SRC shell
pip freeze > requirements.txt
#+END_SRC

capture the required libraries in the file requirements.txt

*** Install libraries according to requirements

#+NAME:pip_install_according_requirements
#+BEGIN_SRC shell
pip install -r requirements.txt
#+END_SRC

Where requirements.txt is the output from pip freeze > requirements.txt

requirements.txt may have the following content for example:
#+BEGIN_EXAMPLE
simplegeneric==0.8.1
# SimpleWebSocketServer==0.1.0
six==1.11.0
toolz==0.8.2
torch
torchvision==0.2.0
tornado==4.5.3
#+END_EXAMPLE

It's possible to comment out item required.

With the presence of ==0.8.2 it will installs the library with the particular
version.

Without version, it will just install the latest available.

*** Create virtualenv

There are quite a few approaches.

- pyenv
-

**** Working with pyenv


***** installation

 The following link has good instruction.
 https://amaral.northwestern.edu/resources/guides/pyenv-tutorial

 It almost work. Except that any
 potential change to ~/.bashrc will only take effect in a new shell or after
 executing

 #+NAME:source_bashrc
 #+BEGIN_SRC shell
source ~/.bashrc
 #+END_SRC

 The following commands works for installation, while the other alternative
 didn't work for me at Ubuntu 16.04

 #+NAME:install_pyenv
 #+BEGIN_SRC shell
cd
git clone git://github.com/yyuu/pyenv.git .pyenv
echo 'export PYENV_ROOT="$HOME/.pyenv"' >> ~/.bashrc
echo 'export PATH="$PYENV_ROOT/bin:$PATH"' >> ~/.bashrc
echo 'eval "$(pyenv init -)"' >> ~/.bashrc
source ~/.bashrc
 #+END_SRC

 Note, the key to source ~/.bashrc

***** Some useful commands

pyenv global
shows the global state of pyenv

pyenv global 3.6.3
make python 3.6.3 to be the global python version

pyenv gloabl system
make system installation python as the global

pyenv local
shows the local python selected

pyenv local 3.6.3
makes python 3.6.3 the local python version

pyenv versions
show python versions available

pyenv install 3.6.3
install a particular python version under pyenv

***** Make a local selection of python version

It seems that it has to be an empty directory,
#+NAME:select_local_python_version
#+BEGIN_SRC shell
mkdir a_new_project
cd a_new_project
pyenv local 3.6.3
source ~/.bashrc # a must! or start a new shell as equivalent
python -V # new local python version shown
cd ..
python -V # gloabl (default) python version shown
#+END_SRC

***** Create virtualenv with pyenv

#+NAME:install_virtualenv_plugin
#+BEGIN_SRC shell
git clone https://github.com/yyuu/pyenv-virtualenv.git ~/.pyenv/plugins/pyenv-virtualenv
source ~/.bashrc
#+END_SRC

#+NAME:create_virtualenv
#+BEGIN_SRC shell
cd ~
mkdir ~/virtual_env
cd virtual_env/
pyenv virtualenv 3.6.3 udacity_workspace
pyenv activate udacity_workspace
#+END_SRC

#+NAME:deactivate_virtualenv
#+BEGIN_SRC shell
pyenv deactivate
#+END_SRC



*** Note, Python library may be made available by different library name.

For example, for skvideo, it can be installed by the following:

#+NAME:install_skvideo
#+BEGIN_SRC shell
pip install scikit-video
#+END_SRC

and for PIL

#+NAME:install_PIL
#+BEGIN_SRC shell
pip install pillow
#+END_SRC

*** Note, path or directory for storing python package *.pth files must be provisioned

- Having the path as part of PYTHONPATH is one of the easier way to provision:

#+NAME:add_path_for_python_pth_files
#+BEGIN_SRC shell
export PYTHONPATH=$PYTHONPATH:/home/yubrshen/.local/lib/python3.6/site-packages
#+END_SRC

The above command provision /home/yubrshen/.local/lib/python3.6/site-packages to
store *.pth python package/library.

Such command typically is placed in ~/.bashrc

*** To install pygpu, pip install pygpu does not work, the following may work:

https://github.com/roebius/deeplearning_keras2/files/1332072/install_gpuarray_pygpu.sh.zip

*** with matplotlib.pyplot.imshow(image), the value of image is assumed to either float in [0, 1] or integer [0, 255]

    For float value, if it's larger than 1 or smaller than 0, will be clipped.
    This may cause problem if the image is type float, but the value is actually
    in [0.0, 255.0] converted from integer [0, 255], then it will be clipped to
    be in the range of [0.0, 1.0] removing almost all those values larger than
    1.0. The image would be severely distorted when shown by imshow, but the
    actualy value of the array of arrays, just have type difference.

    Fortunately, imshow will show the error message: "Clipping input data to the
    valid range for imshow with RGB data ([0..1] for floats or [0..255] for
    integers)"
otherwise, the values will be clipped to be in the range!

*** In Tensorflow, a tensor is just a device (object) to express the value (how to compute the value), but not the value itself

    To get the concrete value that a tensor represents, it should be executed
    within a session environment, for example,

#+NAME:evaluate_tensor
#+BEGIN_SRC python :noweb no-export :tangle
a_tensor = tf.constant([1, 2, 3], dtype=tf.uint8)

with tf.Session() as sess:
    sess.run(a_tensor)
#+END_SRC

*** Note, I have both pip and miniconda3 environment setting up for Python development

    I may choose to either one for convenience

* Handy for projects

To view the trajectory of the car based on the data from the rosbag
#+BEGIN_SRC shell
rosrun tools diagScreenRosbag.py
#+END_SRC

To view the trajectory of the car in simulator with bigger screen size, and appropriate font size
#+BEGIN_SRC shell
rosrun tools diagScreen.py --screensize 3 --fontsize 1
#+END_SRC


* Handy SQL Database

** Create a database

create a database with Microsoft SQL Operations Studio

Create a database DWPractice, if it doesn't exist in sys.database

#+BEGIN_EXAMPLE
USE master
GO
IF NOT EXISTS (
   SELECT name
   FROM sys.databases
   WHERE name = N'DWPractice'
)
CREATE DATABASE [DWPractice]
GO

ALTER DATABASE [DWPractice] SET QUERY_STORE=ON
GO
#+END_EXAMPLE




** Reference to table in SQL (Mircorsoft SQL server)

   Fully qualified table address:

   [database-host-server].[DB-name].[schema-name].[table-name]

   For example,
   [OtherServerName].[OtherDB].[dbo].[OtherTable]

** To access other databases

   Usually a client is connected to one database, to connect additional
   database(s) (Linked Databases), in Microsoft SQL Server, use the store procedure:

   sp_addlinkedserver: http://msdn.microsoft.com/en-us/library/ms190479.aspx

   or you can get to them in SSMS from the following location in the tree of the Object Explorer:

   Server Objects-->Linked Servers

   SSMS = Microsoft SQL Server Management Studio


** User Guides to Microsoft SQL Operations Studio (SOPS)

The following one is a good one.
https://www.red-gate.com/simple-talk/sql/sql-tools/walk-around-sql-operations-studio/

This one seems also quite comprehensive:
http://blog.sqlterritory.com/2017/12/19/sql-operations-studio-comprehensive-guide/

** The concept of "explain" in Microsoft SQL Operations Studio (SOPS)

   It's like a dry run to show how a script of SQL statements would be executed
   to see how feasible or optimal it is.

** It's possible to add constraint of foreign key after a table is created and content inserted

Here is an example,
#+BEGIN_SRC sql
ALTER TABLE [dbo].[Sales_F]
ADD CONSTRAINT [FK_Sales_F_City_Id] FOREIGN KEY (City_Id) REFERENCES [dbo].[City_D] (City_Id)
ALTER TABLE [dbo].[Sales_F]
ADD CONSTRAINT [FK_Sales_F_Prod_Id] FOREIGN KEY (Prod_Id) REFERENCES [dbo].[Prod_D] (Prod_Id)
#+END_SRC

Note, ALTER TABLE [dbo].[Sales_F] is needed for each added constraint.


** Connect to SQL server of Microsoft

Using SSMS:
https://docs.microsoft.com/en-us/sql/linux/sql-server-linux-develop-use-ssms

Provide the host IP address, the database server username and password.




** Gotcha: LineNo in Microsoft SQL Server is a reserved word should not be used as filed name!

https://stackoverflow.com/questions/4054511/what-exactly-does-the-t-sql-lineno-reserved-word-do

The symptom would be when 'LineNo' is used as field name, the editor would show
syntax error around 'LineNo'.


** With Microsoft SQL Server, Date and DateTime accept usual literal form in strings

   https://stackoverflow.com/questions/12957635/sql-query-to-insert-datetime-in-sql-server

https://technet.microsoft.com/en-us/library/ms180878(v=sql.105).aspx#StringLiteralDateandTimeFormats

Unlike Oracle or MySQL, no procedure of transformation of to_date, etc. is
needed.

But Microsoft SQL Server does support CAST and CONVERT to do the transformation.



** Never select region of text in SQL script editor of SSMS or SOPS of Microsoft when running the script

   Or, it will only execute the seletect the text as store procedure, instead of
   the whole script in the editor.

   https://stackoverflow.com/questions/25270305/initial-error-when-querying-sql-server-2012-database


** Change to table definitions

https://www.techonthenet.com/sql_server/tables/alter_table.php

Especially, for Microsoft SQL (Transact-SQL), one should use sp_rename to rename
a column (field) name.



** To be able to access all tables in different database in a database server?

The table name must be fully qualified with database name, schema name and
table name to let the statement block work. For example,

#+NAME:using-properties
#+BEGIN_SRC sql :noweb no-export :tangle
select * from OtherDW.dbo.Supplier_D
#+END_SRC

#+RESULTS: using-properties
| Supplier_Id | Supplier_Name |
|-------------+---------------|
|           1 | Walmart       |
|           2 | Amazon        |


** to execute SQL code block org-mode (literate DBMS) with Mircorsoft SQL Server on Ubuntu

Here is an good example of literate DBMS:
http://www.howardism.org/Technical/Emacs/literate-database.html

So far to to be execut SQL block in org-mode with Microsoft SQL Server,
the header arguments must be explicitly placed at the header of an SQL block.
(Defining them as properties doesn't work! It is supposed to work per
https://www.gnu.org/software/emacs/manual/html_node/org/Header-arguments-in-Org-mode-properties.html
)

#+NAME:test
#+BEGIN_SRC sql :noweb no-export :tangle :engine mssql :cmdline "-S localhost -U SA -P 27Wangzi15"
select * from [DWPractice].[dbo].[Sales_F]
#+END_SRC

#+RESULTS: test
| City_id | Prod_id |      Month | Customer_Id | Supplier_Id | Units | Dollars |
|---------+---------+------------+-------------+-------------+-------+---------|
|       1 |     288 | 2008-01-01 |           3 |           1 |     4 |  7.3200 |
|       1 |     288 | 2008-02-01 |           1 |           1 |    16 | 42.4000 |
|       1 |     589 | 2008-01-01 |           1 |           2 |     3 |  7.9500 |
|       2 |     288 | 2008-01-01 |           2 |           2 |     4 |  7.3200 |
|       2 |     589 | 2008-01-01 |           2 |           1 |     3 |  7.9500 |

#+NAME:test-1
#+BEGIN_SRC sql :noweb no-export :tangle :engine mssql :cmdline "-S localhost -U SA -P 27Wangzi15"
select * from OtherDW.dbo.Supplier_D
#+END_SRC

#+RESULTS: test-1
| Supplier_Id | Supplier_Name |
|-------------+---------------|
|           1 | Walmart       |
|           2 | Amazon        |


*** Use global properties in org-mode
 But using global properties setting would work:
 #+PROPERTY: header-args:sql :engine mssql :cmdline -S localhost -U SA -P 27Wangzi15



** A very practical web site on SQL tips

https://blog.sqlauthority.com/2009/07/17/sql-server-two-methods-to-retrieve-list-of-primary-keys-and-foreign-keys-of-database/
* Handy Networking

** Check whether a port is opened or not in Unix/Linux/Ubuntu

good ways to find out what ports are listenting and what your firewall rules are:

    sudo netstat -tulpn

    sudo ufw status
https://askubuntu.com/questions/9368/how-can-i-see-what-ports-are-open-on-my-machine

** Find out the IP address of my computer of Ubuntu

ifconfig

looking for the interface with the significant traffic.

Or,

route

looking for the line start with 'default'.



* Handy with system

** Use of docker to ease environment setup

Here is a typical setting up an environment:

#+NAME:
#+BEGIN_SRC shell
sudo docker run -p 8888:8888 andrewjstryker/taboo
#+END_SRC

The above command will take care of downloading and setting up the expected
environment.

In Ubuntu, sudo is needed.

* Inbox

** How to use pyenv virtualenv with jupyter lab?

** How to use pyenv virtualenv with emacs?


** The problem of not able to import tensorflow with tensorflow-gpu

   The current problem is that the cuda installed is of version 9.1, but
   tensorflow-gpu expects cuda version 9.0

   Now, I need to install cuda 9.0

   I was only able to install cuda 9.0

   By the following link:

   https://developer.nvidia.com/cuda-90-download-archive?target_os=Linux&target_arch=x86_64&target_distro=Ubuntu&target_version=1604&target_type=runfilelocal

   with runfile (shell script), not with deb file (apt install cuda)

   It seems that my apt system setup might have something wrong with Nvida
   repository. I kept getting the error of "not able to locate cuda".


   The problem is that tensorflow-gpu expects particular version of cudu, not
   the latest, or whatever installed. I have to install the exact cuda version
   to make it work.


** not found: cv2 in python library

#+NAME:install_cv2
#+BEGIN_SRC shell
pip install opencv-python
#+END_SRC



** The problem of "ValueError: Fetch argument 'logits' cannot be interpreted as a Tensor." ("The name 'logits' refers to an Operation not in the graph.")

   When retrieving tensor logits from saved model.

   I don't really fully understand how the save model work. Try to use the other
   way, checkpoint, as an alternative.


*** For tensorflow.argmax to work, output_type=tf.int32 must be in the parameter list

Otherwise, it will have the error of
"tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray dtype
is int64 but Op is trying to write dtype int32."

as shown in the following error trace:

Traceback (most recent call last):
  File "train.py", line 406, in <module>
    run()
  File "train.py", line 389, in run
    logits, keep_prob, image_input)
  File "train.py", line 345, in save_inference_samples
    for name, image, marked in image_outputs:
  File "train.py", line 314, in gen_test_output
    im_labels = segment(image, sess, logits, image_input, keep_prob)
  File "train.py", line 291, in segment
    tf.argmax(logits, axis=1, output_type=tf.int64))], feed_dict = feed)
  File "/home/yubrshen/.pyenv/versions/udacity_workspace/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 900, in run
    run_metadata_ptr)
  File "/home/yubrshen/.pyenv/versions/udacity_workspace/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1135, in _run
    feed_dict_tensor, options, run_metadata)
  File "/home/yubrshen/.pyenv/versions/udacity_workspace/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1316, in _do_run
    run_metadata)
  File "/home/yubrshen/.pyenv/versions/udacity_workspace/lib/python3.6/site-packages/tensorflow/python/client/session.py", line 1335, in _do_call
    raise type(e)(node_def, op, message)
tensorflow.python.framework.errors_impl.InvalidArgumentError: TensorArray dtype is int64 but Op is trying to write dtype int32.
	 [[Node: map/while/TensorArrayWrite/TensorArrayWriteV3 = TensorArrayWriteV3[T=DT_INT32, _device="/job:localhost/replica:0/task:0/device:CPU:0"](map/while/TensorArrayWrite/TensorArrayWriteV3/Enter, map/while/Identity/_225, map/while/TensorArrayWrite/value, map/while/Switch_1/_227)]]
	 [[Node: map/while/TensorArrayWrite/TensorArrayWriteV3/_229 = _Recv[client_terminated=false, recv_device="/job:localhost/replica:0/task:0/device:GPU:0", send_device="/job:localhost/replica:0/task:0/device:CPU:0", send_device_incarnation=1, tensor_name="edge_309_map/while/TensorArrayWrite/TensorArrayWriteV3", tensor_type=DT_FLOAT, _device="/job:localhost/replica:0/task:0/device:GPU:0"](^_cloopmap/while/NextIteration_1/_158)]]

Even though, the document said that output_type is optional and default to
tf.int64,

This happened as of May 24, 2018.



* Shell: invoke the previous command !!

For example, if the first command is the following:

#+NAME:shell
#+BEGIN_SRC python :noweb no-export :tangle
ls -lt
#+END_SRC

If I want to do sudo ls -lt
then
#+NAME:
#+BEGIN_SRC shell
sudo !!
#+END_SRC

!! will substitute the previous command.

Even it can be used to invoke the previous command alone.

* Shell: reuse the arguments of the previous command: !@

* Shell: enable to enter into vi editor for command line editing (not working)
#export VISUAL=vi
#Note in my Ubuntu 16.04 environment export VISUAL=vi resulting shell not able to type character 'e'

So the following does not work for me in Ubuntu 16.04

#+NAME:
#+BEGIN_SRC shell
export VISUAL=vi
#+END_SRC

Put the above command in ~/.inputrc, to enable to invoke vi for command line
editing:

in a command line, when needing to invoke vi to edit the current command line,
press ESC, then v, the vi editor will be invoked with the current command line
as the content,
after editing, save the content by :wq, then the content of the command will be
executed.

* Shell: enable vi for command line editing

#+NAME:
#+BEGIN_SRC shell
set editing-mode vi
#+END_SRC

Put the command in ~/.inputrc to make the behavior permanent.

* Shell: append content to a file

#+NAME:
#+BEGIN_SRC shell
echo "set editing-mode vi" >> ~/.inputrc
#+END_SRC

* Shell: more flexible access of file's tail by using less with command SHIFT-f

In the less command display, press SHIFT-f will move to the end of the file.
Then Ctrl-C will exit to the end of the file resuming the ordinary less file
browsing.

* Shell: clear or reset the current shell

#+NAME:
#+BEGIN_SRC shell
clear
#+END_SRC

Clear the display in the current shell

#+NAME:
#+BEGIN_SRC shell
reset
#+END_SRC

Reset the shell. It's not clear to me what's been reset.

* emacs: undo C-/, redo C-?

This is proven to be working.

* emacs: spacemacs Cycle themes with SPC T n

  To select a theme available.
* emacs: export org-mode to PDF with Chinese text in unicode

adding following option to the org document.
#+LATEX_HEADER: \usepackage{xltxtra}
#+LATEX_HEADER: \setmainfont{WenQuanYi Micro Hei}

Also need to customize emacs latex to pdf process.

(setq org-latex-to-pdf-process
      '("xelatex -interaction nonstopmode -output-directory %o %f"
        "xelatex -interaction nonstopmode -output-directory %o %f"
        "xelatex -interaction nonstopmode -output-directory %o %f"))
PS: The main font has been setted may be vary among different systems. How I
      find a proper font under ubuntu is via command fc-list.

This is based on https://freizl.github.io/posts/2012-04-06-export-orgmode-file-in-Chinese.html

* emacs: org-mode with Chinese text exported to PDF, must add space between the Chinese words (phrases)

In order to let xelatex do proper line wrapping, otherwise, it will treat the
whole of Chinese text as one word causing hbox overflow errors.

By the same token, use ascii number rather than unicode numbers as much as
possible to make line wrapping easier.


* How to update latexmk

latexmk is a make program for latex.

Download the a desired version (latest) from http://personal.psu.edu/jcc8//software/latexmk-jcc/
extract latexmk.pl into a directory, say ~/tmp/latexmk/
cd into that directory:
#+NAME:install_latexmk
#+BEGIN_SRC shell
sudo cp ./latexmk.pl /usr/bin/latexmk
#+END_SRC

* Python: example of assignment to list from list

#+NAME:
#+BEGIN_SRC python :noweb no-export :tangle
name, *line = input().split()
#+END_SRC

* Juypter notebook: add tags to a cell

First make the field and the icon of "add tag" visible, by selecting View -> Cell
Toolbar -> Tags

Then there is a button with label "Add Tags" on the top right corner above a
cell. The icon "..." edit the existing tags, and a field to add new tag are just
to the left of the label "Add Tags", right justified. (The button actually does
not sever as a button, but just a label to indicate the field and the icon next
to it. It might be more helpful to provide hint when one clicks on the button on
how to add tags.)

The problem: the borders of the field to add tags, as well as the icon "..." for editing the tags for a cell is too faint that it's hardly visible for people with color blindness, causing them not able to figure out how to add tags to the cell.

The solution: make the borders and the icon have greater contrast to be more
visible even for the color blinded.

* Jupyter notebook: cell toolbar

Cell toolbar provides more functionality related to a particular cell. The
functionalists includes adding tags, adding meta data, arrange the cell for
slide, etc.

It's accessible by View -> Cell Toolbar ->



* Python: Capitalize words preserving the number of spaces

#+NAME:
#+BEGIN_SRC python :noweb no-export :tangle
import string
def solve(s):
  return string.capwords(s, ' ')
#+END_SRC

string.capwords with ' ' as the argument for separator will preserve the number
of spaces between the words.


* Flutter tbx

** Create a new project from command line

#+NAME:
#+BEGIN_SRC shell
flutter create hello_rectangle
#+END_SRC

** Run flutter project from command line

Inside the directory of the project:

#+NAME:
#+BEGIN_SRC shell
flutter run
#+END_SRC


** The sample code from Google/Udacity Flutter course

https://github.com/flutter/udacity-course/tree/master/course/01_hello_rectangle/solution_01_hello_rectangle
https://github.com/flutter/udacity-course

** For the problem missing AVD (Android Virtual Device) manager

   I ran into the problem that I could not find AVD in Android Studio Tools
   menu.

   The problem was solved by resetting SDK selection/path and restart the
   Android Studio. The SDK selection is set to 'Android API 28 Platform'.

   The setting of SDK is via Android Studio menu File/Project Structure/SDK

   AVD is required to start the Android emulator.

   Note, the above solution does not persist. After quitting, when restarting,
   the menu for Tool/Android/AVD manager disappeared again.


** To start AVD from command line

#+NAME:
#+BEGIN_SRC shell
~/Android/Sdk/emulator/emulator @AVD_name
#+END_SRC


** Alternative way to access AVD manager and start emulator

   In Android Studio, with menu Help/Find Action, in the input panel enter AVD
   manager, and double click mouse on the first found entry, it will launch AVD
   manager. (With AVD manager, one can start the AVD (Android Virtual Device).

   This tricks works well with Android Studio version 3.1.3, when the menu for
   AVD manager disappeared in Tools/


** The feedback of starting AVD manager inside Android Studio

The error message's summary is shown at the left bottom of Android Studio.
Double click on the summary will show the detailed message.


** Solution to "emulator: ERROR: Not enough disk space to run AVD <emulator-name> Exiting" with AVD manager or command line to start an AVD

1. Wipe out the AVD's data per https://stackoverflow.com/questions/26593711/android-5-0-emulator-showing-storage-space-running-out

2. Increase the size of memory in the AVD configuration
3. Make sure the directory where ~/.android is has enough space


** Re-install Android studio to solve the crash when starting the studio

   Re-install flutter at ~/programming/flutter
   Remove Android/Sdk (default at ~/Android/Sdk)
   Remove ~/.android
   Remove ~/.AndroidStudio3.1

   Re-install studio by
   1. Download the file for Linux;
   2. Extract from the zip file
   3. From the extracted, executing android-studio/bin/studio.sh and follow the
   wizard, select custom installation, install the Sdk at a custom location,
   update ANDROID_HOME to reflect the custom location in ~/.bashrc

   Use flutter doctor -v to diagnose problems.

   To launch the studio again, execute studio.sh

   Overall, following the "Getting Started" guide of Flutter.

   Here is a guide helpful for complete uninstall: https://askubuntu.com/questions/546723/uninstall-android-studio-completely

* The best regular expression developer

It's online:

https://regex101.com/

* Python: note the different semantics of groupby than that in Pandas or in SQL

  Its semantics can be illustrated as following:

  # [k for k, g in groupby('AAAABBBCCDAABBB')] --> A B C D A B
  # [list(g) for k, g in groupby('AAAABBBCCD')] --> AAAA BBB CC D

  It only extracts the consecutive elements' the sameness according to a mapping
  function. In Clojure, there is a similar function.


* Trick to make multiple monitors working with Ubuntu 16.04 and my external monitor

  Sometimes, it does not work to have the external monitor on top of the
  built-in display, even with setting with Displays setting software and ARandR.
  It would make the external monitor black.

  The work-around is to use ARandR to have the HDMI as the sole display, then
  re-set with ARandR to be of vertical setting. It worked in my attempt on Aug.
  2nd, 2018.

* Tricks of coding with word processor Google doc or Microsoft Wrod

  Try to use ''' ''' for block comment, to make it easier to write arbitrary
  length of comments.

  Turn off smart quote to keep the block comment.

  Use a lots of comment to expression the intention to easier understand, when
  the format might not be fully working or correct.

* Send links to desktop from wechat

  Open wechat application on desktop in browser, then from the wechat session in
  mobile phone send the links to a special "user" file transfer. At the desktop
  session, one can access the links.
